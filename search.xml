<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Wuenda&#39;s class(2)</title>
      <link href="/2020/08/20/wuenda-s-class-2/"/>
      <url>/2020/08/20/wuenda-s-class-2/</url>
      
        <content type="html"><![CDATA[<h3 id="p1-Train-dev-test-sets"><a href="#p1-Train-dev-test-sets" class="headerlink" title="p1.Train/dev/test sets"></a>p1.Train/dev/test sets</h3><blockquote><p>Train：训练集，用来训练各种模型</p><p>dev：验证集(development set)/Hold-out cross validation set，评估这些模型，通过迭代选出最优模型</p><p>test：测试集，需要对最终选定的神经模型进行最优估计（可选）</p><p>[^小数据集Train:dev:test=6:2:2 数据集较大（eg：100万data验证集和测试集可能只达到0.25%）]: </p><p>dev,test选择的数据来源需相同，才能有更好的效果</p></blockquote><h3 id="p2Bias-Variance偏差-方差"><a href="#p2Bias-Variance偏差-方差" class="headerlink" title="p2Bias/Variance偏差/方差"></a>p2Bias/Variance偏差/方差</h3><p>high bias:underfitting</p><p>high variance: overfitting</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200820092101036.png" alt="image-20200820092101036"></p><p>[^Train set error 小，dev set error大说明过拟合方差大 ；Train set error 大，dev set error小说明欠拟合偏差大]: </p><h3 id="p3机器学习基础"><a href="#p3机器学习基础" class="headerlink" title="p3机器学习基础"></a>p3机器学习基础</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200820095910120.png" alt="image-20200820095910120"></p><h4 id="P4Regulation"><a href="#P4Regulation" class="headerlink" title="P4Regulation"></a>P4Regulation</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200820101622245.png" alt="image-20200820101622245"></p><h4 id="P5How-does-regularization-prevent-overfitting"><a href="#P5How-does-regularization-prevent-overfitting" class="headerlink" title="P5How does regularization prevent overfitting"></a>P5How does regularization prevent overfitting</h4><p><img src="http://www.ai-start.com/dl2017/images/1a6c47e64293cde6a0facb3872701db2.png" alt="img"></p><p>if正则化参数设置的足够大，权重矩阵被设置为接近为零，基本上消除了隐藏的影响。这样就会从过拟合的状态接近高偏差的状态。</p><p>但会存在一个中间值，即“Just Right”状态。消除或减少许多隐藏单元的影响，神经网络会越来越接近逻辑回归，所有隐藏单元依然存在，但是神经网络变简单了。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822091610507.png" alt="image-20200822091610507"></p><p>如果正则化参数变得很大，参数W很小，z也会相对变小，此时忽略b的影响，z会相对变小，实际上，z的取值范围很小，这个激活函数，也就是曲线函数tanh会相对呈线性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的高度非线性函数，不会发生过拟合。</p><h3 id="Dropout-regularization（主要应用在cv）"><a href="#Dropout-regularization（主要应用在cv）" class="headerlink" title="Dropout regularization（主要应用在cv）"></a>Dropout regularization（主要应用在cv）</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822091810868.png" alt=""></p><p>[^keep_prob:保留每一个节点的概率。]: </p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822092105257.png" alt="image-20200822092105257"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822092632822.png" alt="image-20200822092632822"></p><p>如果某些层需要去除过拟合，那么keep_prob就需要设置的大一些。</p><h3 id="p9归一化输入"><a href="#p9归一化输入" class="headerlink" title="p9归一化输入"></a>p9归一化输入</h3><blockquote><p>一种加速神经网络训练速度的方法。</p></blockquote><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822093306498.png" alt="image-20200822093306498"></p><p>右图比左图的代价函数更容易找到min值，有图需要梯度下降迭代寻找。</p><h3 id="p10Vanishing-exploding-gradients"><a href="#p10Vanishing-exploding-gradients" class="headerlink" title="p10Vanishing/exploding gradients"></a>p10Vanishing/exploding gradients</h3><p>Vanishing gradients：接近于输出层的隐藏层由于其梯度相对正常，权值更新也相对正常。越靠近输入层，由于gradients消失，会导致靠近输入层权值更新缓慢或者停止。此时就导致训练时只等价于后面几层的浅层网络的学习。</p><h5 id="p9-1-换用Relu、LeakyRelu、Elu等激活函数"><a href="#p9-1-换用Relu、LeakyRelu、Elu等激活函数" class="headerlink" title="p9.1 换用Relu、LeakyRelu、Elu等激活函数"></a>p9.1 换用Relu、LeakyRelu、Elu等激活函数</h5><p>ReLu：让激活函数的导数为1</p><p>LeakyReLu：包含了ReLu的几乎所有有点，同时解决了ReLu中0区间带来的影响</p><p>ELU：和LeakyReLu一样，都是为了解决0区间问题，相对于来，elu计算更耗时一些（为什么）</p><p>具体可以看<a href="#activation">关于各种激活函数的解析与讨论</a></p><h5 id="p9-2-BatchNormalization"><a href="#p9-2-BatchNormalization" class="headerlink" title="p9.2 BatchNormalization"></a>p9.2 BatchNormalization</h5><p>BN本质上是解决传播过程中的梯度问题，具体待补充完善，查看<a href="...">BN</a></p><h5 id="p9-3-ResNet残差结构"><a href="#p9-3-ResNet残差结构" class="headerlink" title="p9.3 ResNet残差结构"></a>p9.3 ResNet残差结构</h5><p>具体待补充完善，查看<a href="...">ResNet</a></p><h5 id="p9-4-LSTM结构"><a href="#p9-4-LSTM结构" class="headerlink" title="p9.4 LSTM结构"></a>p9.4 LSTM结构</h5><p>LSTM不太容易发生梯度消失，主要原因在于LSTM内部复杂的“门（gates）”</p><h5 id="p9-5-预训练加finetunning"><a href="#p9-5-预训练加finetunning" class="headerlink" title="p9.5 预训练加finetunning"></a>p9.5 预训练加finetunning</h5><p>此方法来自Hinton在06年发表的论文上，其基本思想是每次训练一层隐藏层节点，将上一层隐藏层的输出作为输入，而本层的输出作为下一层的输入，这就是逐层预训练。</p><p>训练完成后，再对整个网络进行“微调（fine-tunning）”。</p><p>此方法相当于是找全局最优，然后整合起来寻找全局最优，但是现在基本都是直接拿imagenet的预训练模型直接进行finetunning。</p><h3 id="4-5-梯度剪切、正则"><a href="#4-5-梯度剪切、正则" class="headerlink" title="4.5 梯度剪切、正则"></a>4.5 梯度剪切、正则</h3><p>这个方案主要是针对梯度爆炸提出的，其思想是设值一个剪切阈值，如果更新梯度时，梯度超过了这个阈值，那么就将其强制限制在这个范围之内。这样可以防止梯度爆炸。</p><p>另一种防止梯度爆炸的手段是采用权重正则化，正则化主要是通过对网络权重做正则来限制过拟合，但是根据正则项在损失函数中的形式：</p><p>可以看出，如果发生梯度爆炸，那么权值的范数就会变的非常大，反过来，通过限制正则化项的大小，也可以在一定程度上限制梯度爆炸的发生。</p><h3 id="p32softmax回归"><a href="#p32softmax回归" class="headerlink" title="p32softmax回归"></a>p32softmax回归</h3><p>可以将输入数据分为多类。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822102947253.png" alt="image-20200822102947253"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822103103845.png" alt="image-20200822103103845"></p><p>[^直线边界代表决策边界]: </p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822103500570.png" alt="image-20200822103500570"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822104116682.png" alt="image-20200822104116682"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822104242011.png" alt="image-20200822104242011"></p><h3 id="Class-5-sequence-data-nlp-Natural-Language-Processing"><a href="#Class-5-sequence-data-nlp-Natural-Language-Processing" class="headerlink" title="Class 5 sequence data-nlp(Natural Language Processing)"></a>Class 5 sequence data-nlp(Natural Language Processing)</h3><h4 id="p2Notation"><a href="#p2Notation" class="headerlink" title="p2Notation"></a>p2Notation</h4><h5 id="Reprsenting-words"><a href="#Reprsenting-words" class="headerlink" title="Reprsenting words"></a>Reprsenting words</h5><p>one-hot编码（UNK表示未标识）</p><h4 id="p3Recurrent-Neural-Network"><a href="#p3Recurrent-Neural-Network" class="headerlink" title="p3Recurrent Neural Network"></a>p3Recurrent Neural Network</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200822110650134.png" alt="image-20200822110650134"></p><p>[^X&lt;1&gt;,….，X <t>表示对目标序列的索引]</t></p><h3 id="RNN-Recurrent-Neural-Networks"><a href="#RNN-Recurrent-Neural-Networks" class="headerlink" title="RNN(Recurrent Neural Networks)"></a>RNN(Recurrent Neural Networks)</h3><blockquote><p>传统神经网络有两个缺点：</p><p>1.输入和输出序列的长度必须一致。</p><p>2.不同位置的特征无法</p></blockquote><p>RNN只是用了之前的信息来预测当时的信息</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>text knowledge-gragh transformers</title>
      <link href="/2020/08/15/text-knowledge-gragh-transformers/"/>
      <url>/2020/08/15/text-knowledge-gragh-transformers/</url>
      
        <content type="html"><![CDATA[<h3 id="Name"><a href="#Name" class="headerlink" title="Name:"></a>Name:</h3><p><strong>Text Generation from Knowledge Graphs with Graph Transformers</strong></p><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><blockquote><p> ​    Generating texts which express complex ideas spanning multiple sentences requires a structured representation of their content (document plan), but these representations are prohibitively expensive to manually produce. </p><p> ​    生成包含复杂含义并且横跨多个句子的文本需要一种对他们文章结构化的表达（文本计划），但是这些表达对于自然生产来说却过于昂贵。</p><p>  In this work, we address the problem of generating coherent multi-sentence texts from the output of an information extraction system,and in particular a knowledge graph. Graphical knowledge representations are ubiquitous in computing, but pose a signifificant challenge for text generation techniques due to their non-hierarchical nature, collapsing of long distance dependencies, and structural variety.</p><p> ​    本文解决了从信息提取系统，特别是知识图谱中生成连续多个句子组成的文本的难题。图形知识对计算机而言是独特的，但由于文本技术无等级的性质，长距离依赖的崩溃以及结构的多样性，图形知识生成技术对于文本生成技术也是一个挑战。</p><p> We introduce a novel graph transforming encoder which can leverage the relational structure of such knowledge graphs without imposing linearization or hierarchical constraints.</p><p> 我们介绍一种创新的图转化编码器，这种编码器可以在没有线性和等级限制的前提下，利用这种知识图谱的关系结构。</p><p> Incorporated into an encoder-decoder setup,we provide an end-to-end trainable system for graph-to-text generation that we apply to the domain of scientifific text. Automatic and human evaluations show that our technique produces more informative texts which exhibit better document structure than competitive encoder-decoder methods.</p><p> 结合编码解码器我们为在科学文本领域应用的图到文本生成器提供了一种端到端的训练系统。自动和人工的测量展现了我们的技术生产出更多含义丰富的文本，这些文本相对于有竞争力的编码解码器展现出更好的文档结构。</p></blockquote><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><blockquote><p>​    Increases in computing power and model capacity have made it possible to generate mostly grammatical sentence-length strings of natural language text. However, generating several sentences related to a topic and which display overall coherence and discourse-relatedness is an open challenge. The difficulties are compounded in domains of interest such as scientific writing.</p></blockquote><p>计算能力和模型容量的增强和增大使得生成主要是自然语言文本的语法句子长度成为可能。然而，生成一些与主题相关的句子并且显示出整体一致性和语篇相关性是一个公开的挑战。这些困难在像科学写作的兴趣领域中变得更为复杂。</p><blockquote><p>Additionally, there are strong constraints on document structure, as scientifific communication requires carefully ordered explanations of processes and phenomena.</p></blockquote><blockquote><p>另外，对于文档结构而言有强的限制，作为科学文档需要对过程和现象进行仔细有趣的解释有序的解释。之前研究者们采用手动注释的方法，现在就采用自动注释的方法，但是存在但由于它们的自动性，它们也给生成带来了挑战，如错误注释、结构多样性和表面文本特征(如GR)的显著抽象 语法关系或谓词结构)。</p></blockquote><blockquote><p>​        To effect our study, we use a collection of abstracts from a corpus of scientifific articles (Ammar et al., 2018). We extract entity, coreference, and relation annotations for each abstract with a state-of-the-art information extraction system (Luan et al., 2018), and represent the annotations as a knowledge graph* which collapses co-referential entities. An example of a text and graph are shown in Figure 1. We use these graph/text pairs to train a novel attention-based encoder-decoder model for knowledge-graph-to-text generation. Our model,GraphWriter, extends the successful Transformer for text encoding (Vaswani et al., 2017) to graph structured inputs, building on the recent Graph Attention Network architecture (Velickovic et al.,2018). The result is a powerful, general model for graph encoding which can incorporate global structural information when contextualizing vertices in their local neighborhoods.</p></blockquote><p>​            为了实施我们的研究，我们使用了科学杂志语料库的摘要集（Ammar等人，2018），我么使用最先进的信息提取系统提取出了每个摘要集的实体，引用以及关系注释（Luan 等人，2018），并且将注释生成为一个知识图谱，该图谱折叠了一些共同引用的实体。一个关于文本和图的例子在图一中展示。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200818092807792.png" alt="image-20200818092807792"></p><p>我们使用这些图形文本对为了知识图谱到文本的生成器去训练一种创新的基于注意力机制的编码解码器。我们的模型，Graphwriter，将文本编码成功的转换器扩展到图形化的输入。建立在</p><p>最近的图注意力网络结构。这个结果是生成一个强大并且通用的模型，这个模型是针对在目标词上下文进行语境化时能够合并全局结构化信息的图形编码建立的。</p><blockquote><p>The main contributions of this work include:</p><ol><li><p>We propose a new graph transformer encoder that applies the successful sequence transformer to graph structured inputs.</p></li><li><p>We show how IE output can be formed as a connected unlabeled graph for use in attention-based encoders.</p></li><li><p>We provide a large dataset of knowledge graphs paired with scientifific texts for further</p><p>study.</p></li></ol></blockquote><blockquote><p>​    Through detailed automatic and human evaluations, we demonstrate that automatically extracted knowledge can be used for multi-sentence text generation. We further show that structuring and encoding this knowledge as a graph leads to improved generation performance compared to other encoder-decoder setups. Finally, we show that GraphWriter’s transformer-style encoder is more effective than Graph Attention Networks on the knowledge-graph-to-text task.</p></blockquote><p>​         通过详细的自动和人工评估，我们证明了自动提取的知识可以用于多句文本生成。 我们进一步证明了与其他编解码器设置相比，结构化以及将此类知识当作图形进行编码都产生了更好的生成性能。 最后，我们证明了图形写入器的转换器式编码器比在知识图谱到文本任务上的图形注意力网络更有效率。</p><h3 id="3-The-AGENDA-Dataset"><a href="#3-The-AGENDA-Dataset" class="headerlink" title="3.The AGENDA Dataset"></a>3.The AGENDA Dataset</h3><p>我们考虑从自动提取的信息（知识）生成文本的问题。 IE系统可以为各种领域提供高质量的知识，从句子甚至文档边界中综合信息。从知识生成连贯的文本需要一个模型，该模型考虑知识的全局特征以及每个实体的局部特征。这项任务的功能促使我们使用图来表示知识，邻居通过图来定位重要信息，并且路径通过图建立了中间节点之间的远距离节点之间的连接。示例知识图如图1所示。</p><p>我们将问题表达如下：给定科学文章的标题和由自动信息提取系统构建的知识图，目标是生成一个摘要，其中a)适用于给定的标题，b)表示该标题的内容。自然语言文本中的知识图。为了评估模型完成此目标的能力，我们引入了Abstract GENeration DAtaset（AGENDA），这是一个与科学摘要配对的知识图谱数据集。我们的数据集包含来自12个顶级AI会议(Ammar et al.，2018)会议过程的语义学者语料库(Semantic Scholar Corpus)的4万篇论文标题和摘要。</p><p>对于每个摘要，我们分两步创建一个知识图谱。首先，我们应用Luan等人(2018年)的SciIE系统，一个最新的科学领域信息提取系统。该系统提供科学术语的命名实体识别，其实体类型为”Task”，“Method”,“Metric”,“Material”或”Other-Scientific Term”。该模型还产生共参考注释(co-reference annotations)以及可以在不同实体之间获得的七个关系（Compare，Used-for，Feature-of，Hyponym-of，Evaluate和Conjunction）。例如，在图1中，标记为”SemEval 2011 Task 11”的节点的类型为”Task”,“HMM Models”的类型为” Model”，并且存在”Evaluate-For”关系，该关系表明在任务上已被评估模型。</p><p>我们将这些注释形成知识图谱。 我们将共同引用实体折叠到与最长提及相关联的单个节点中（假设这些实体将提供最多信息）。 然后，我们使用关系注释将节点彼此连接，将它们视为图形中的标记边缘。 结果是给定摘要的SciIE注释可能是未连接的图形表示形式。<br>表1中提供了AGENDA数据集的统计信息。我们将AGENDA数据集分为38,720个训练，1000个验证和1000个测试数据点。 我们提供标准化的数据拆分，以方便比较。</p><p><img src="https://img-blog.csdnimg.cn/20200209221151600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FSUE9TUEY=,size_16,color_FFFFFF,t_70" alt="表1"></p><h3 id="4-Model"><a href="#4-Model" class="headerlink" title="4.Model"></a>4.Model</h3><blockquote><p>​        Following most work on neural generation we adopt an encoder-decoder architecture, shown in Figure 3, which we call GraphWriter. The input to GraphWriter is a title and a knowledge graph which are encoded respectively with a bidirectional recurrent neural network and a novel Graph Transformer architecture (to be discussed in Section 4.1). At each decoder time step, we attend on encodings of the knowledge graph and document title using the decoder hidden state ht ∈ Rd. The resulting vectors are used to select output wt either from the decoder’s vocabulary or by copying an entity from the knowledge graph. Details of our decoding process are described in Section 4.2. The model is trained end-to-end to minimize the negative log likelihood of the mixed copy and vocabulary probability distribution and the human authored text.</p></blockquote><p>​        在神经系统生成的大部分工作后，我们生成了一种在图3中展示出来的被称为GraphWriter的编码解码结构。GraphWriter的输入是可以分别用BRNN和新的图形Transformer结构编码的一个标题和一个知识图谱。在每个解码的时间点上，我们使用解码的隐藏状态ht∈Rd对知识图谱和文档标题进行编码。结果向量被用于去从解码器词汇表中选择一个wi输出或者从知识图谱中复制一个实体。解码过程的细节在4.2部分中被描述，这个模型在端到端上被训练去最小化副本、词汇概率分布以及人类创作的文本的负对数似然。</p><h3 id="4-1Encoder"><a href="#4-1Encoder" class="headerlink" title="4.1Encoder"></a>4.1Encoder</h3><blockquote><p>​    The AGENDA dataset contains a knowledge graph for each datapoint, but our model requires unlabeled, connected graphs as input. To encode knowledge graphs with this model, we restructure each graph as an unlabeled connected graph, preserving label information by the method described below and sketched in Figure 2.</p></blockquote><p>​        AGENDA数据集对每个数据点都包含一个知识图谱，但是我们的模型需要无标记、相连接的图谱作为输入。为了用这个模型编码知识图谱，我们将每个图谱作为未标记已连接的图谱，如图2所示通过下面描述的方法保存标签信息。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200823111326465.png" alt="image-20200823111326465"></p><p>[^将未连接已标记的图谱转化成已连接未标记的图谱，作用于基于注意力机制的编码器中。vi是顶点，Rij是关系，G是全局文本节点。]: </p><blockquote><p><strong>Graph Preparation</strong> </p><p>​        We convert each graph to an unlabeled connected bipartite graphs following a similar procedure to Beck et al. (2018). In this process, each labeled edge is replaced with two vertices: one representing the forward direction of the relation and one representing the reverse. These new vertices are then connected to the entity vertices so that the directionality of the former edge is maintained. This restructures the original knowledge graph as an unlabeled directed graph where all vertices correspond to entities and relations in the SciIE annotations without loss of information. To promote information flow between disconnected parts of the graph, we add a global vertex which connects all entity vertices. This global vertex will be used to initialize the decoder, analogously to the fifinal encoder hidden state in a traditional sequence to sequence model. The fifinal result of these restructuring operations is a connected, unlabeled graph <em>G</em> = (<em>V, E</em>), where <em>V</em> is a list of entities, relations, and a global node and<em>E</em> is an adjacency matrix describing the directed edges.</p></blockquote><h3 id="图形准备"><a href="#图形准备" class="headerlink" title="图形准备"></a>图形准备</h3><p>​            我们按照Beck在2018年写的similiar程序将每个图转换成一个未标记的连通二分图。在这个过程中，每个被标记的边被两个顶点代替：一个代表正向关系，另一个代表正向关系，另一个代表反向关系。为了保持前一条边的方向性，这些新的顶点接着被连接到实体顶点。将原始的知识图谱重组成未标记的有向图，其中所有的顶点都对应SciIE注释中的实体和关系，并且没有损失任何信息。为了提升图中非连通部分之间的信息流动，我们增加了一个可以连接实体顶点的全局顶点。这个全局顶点将会被用于初始化解码器，与传统序列到序列模型之间最终的编码隐藏层类似。这些重组操作的最终结果是一个连通的未标记图G=(V,E),V是实体，关系以及一个全局节点的列表。边是一个描述有向边的邻接矩阵。</p><blockquote><p><strong>Graph Transformer</strong> </p><p>Our model is most similar to the Graph Attention Network (GAT) of Velickovic et al. (2018), which computes the hidden representations of each node in a graph by attending over its neighbors following a self-attention strategy. The use of self-attention in GAT addresses the shortcomings of prior methods based on graph convolutions (Defferrard et al.2016; Kipf and Welling, 2017), but limits vertex updates to information from adjacent nodes. Our model allows for a more global contextualization of each vertex through the use of a transformerstyle architecture. The recently proposed Transformer (Vaswani et al., 2017) addresses the inherent sequential computation shortcoming of recurrent neural networks, enabling effificient and paralleled computation by invoking a self-attention mechanism for global context modeling. These models have shown promising results in a variety of text processing tasks (Radford et al., 2018).</p></blockquote><h3 id="图转换器"><a href="#图转换器" class="headerlink" title="图转换器"></a>图转换器</h3><p>​        我们的模型与GAT（图形注意网络）是最相似的，它通过自注意力策略处理邻居顶点来计算图形中每个节点的隐藏表示。在GAT中使用的自注意力机制解决了基于图卷积的现有方法的缺点，但是限制顶点从相邻顶点更新信息。我们的模型允许通过使用transformer类型的结构为每一个顶点进行更全局的上下文化。最近提出的Transformer模型中RNN固有的序列计算的缺点。通过为全局文本模型调用自注意力机制启用高效并行的计算。这些模型在多种文本处理任务中展现出了预期的结果。</p><blockquote><p>​        Our Graph Transformer encoder starts with self-attention of local neighborhoods of vertices; the key difference with GAT is that our model includes additional mechanisms for capturing global context. This additional modeling power allows the Graph Transformer to better articulate how a vertex should be updated given the content of its neighbors, as well as to learn global patterns of graph structure relevant to the model’s objective.</p><p>​        Specififically, <em>V</em> is embedded in a dense continuous space by the embedding process described at the end of this section, resulting in matrix <strong>V</strong>0 = [<strong>v*</strong>i<em>]</em>,* <strong>v*</strong>i* <em>∈</em> R<em>d</em> which will serve as input to the graph transformer model shown in Figure 4. Each vertex representation <strong>v*</strong>i* is contextualized by attending over the other vertices to which <em>v**i</em> is connected in <em>G</em>. We use an <em>N</em>-headed self attention setup, where <em>N</em> independent attentions are calculated and concatenated before a residual connection is applied:</p></blockquote><p>​        我们的图形Transformer编码器编码以顶点的本地令居的自注意力机制为起点，与GAT关键的差异就在于我们的模型包含额外捕捉全局上下文的机制。这个另外的使得图形Transformer能够在考虑邻居节点的前提下如何更新阐明一个顶点，同样也可以学习与模型目标相关的图形结构的全局模式。</p><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200825093359698.png" alt="image-20200825093359698"></p><p>​        特别地，V就像在这个部分最后描述的嵌入过程中那样被嵌入在一个密集的连续空间中，导致生成矩阵V=[vi],vi∈Rd，矩阵作为如图4所示的图形tranformer模型中的输入。每一个顶点的表示vi都是通过处理与vi在图G中相连的其他所有顶点来进行上下文化。我们使用一个N头的自注意力机制，N头独立的注意力机制，这个N头自注意力机制中在被计算和连接之前需要处理剩余的连接：</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825094135094.png" alt="image-20200825094135094"></p><blockquote><p>Here, || denotes the concatenation of the <em>N</em> attention heads, <em>N**i</em> denotes the neighborhood of <em>v**i</em> in <em>G</em>, <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825094704284.png" alt=""> , and where <em>a**n</em> are attention mechanisms parameterized per head. In this work,we use attention functions of the following form:</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825094726513.png" alt=""></p><p>Each a learns independent transformations<strong>W***</strong>Q<strong>,</strong>W<strong><em>K</em> <em>∈</em> R*d</strong>×<strong>d* of **q</strong> and <strong>k</strong> respectively, andthe resulting product is normalized across all connected edges. To reduce the tendency of these dot products to impede gradient flflow, we scale them by <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825095341227.png" alt="">, following Vaswani et al. (2017).The Graph Transformer then augments these multi-headed attention layers with <em>block</em> networks.Each block applies the following transformations:</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825094942641.png" alt=""></p><p>Where FFN(<strong>x</strong>) is a two layer feedforward network with a non-linear transformation <em>f</em> between layersi.e. <em>f</em>(<strong>xW</strong>1 + <em>b</em>1)<strong>W</strong>2 + <em>b</em>2.</p></blockquote><p>​            在这，||表示N注意力头部的连接，Ni表示在图G中的vi的邻居顶点，<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825103417862.png" alt="">)，并且a在每个头部注意力机制被参数化。在这个工作中，我们使用下面公式的注意力结构：<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200825103734156.png" alt=""></p><p>每个a分别学习q和k的独立变换Wq，Wk∈R，并在所有连接的边上对所得乘积进行归一化。为了减少这些点积阻碍梯度流的趋势，我们按照1/根号d缩放。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200826180839842.png" alt="image-20200826180839842"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200826181025088.png" alt=""></p><p><img src="https://img-blog.csdnimg.cn/20200209221457785.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FSUE9TUEY=,size_16,color_FFFFFF,t_70" alt=""></p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>我们研究了从自动信息提取系统的输出中生成多句文本的问题，并表明将知识作为图形进行合并可以提高性能。 我们介绍了GraphWriter，它具有用于图形编码的新注意力模型，并通过与强基准相比的人工和自动评估证明了其实用性。 最后，我们为生成社区提供了一个新资源，即摘要和知识的AGENDA数据集。 未来的工作可能会解决所生成文本中重复和实体覆盖的问题。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://blog.csdn.net/ARPOSPF/article/details/104241533" target="_blank" rel="noopener">https://blog.csdn.net/ARPOSPF/article/details/104241533</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> PaperLookThrough </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gragh transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Word Representation-Sememes</title>
      <link href="/2020/08/12/word-representation-sememes/"/>
      <url>/2020/08/12/word-representation-sememes/</url>
      
        <content type="html"><![CDATA[<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><blockquote><p>Sememes are minimum semantic units of word meanings, and the meaning of each word sense is typically composed by several sememes.</p></blockquote><p>义原是人为标记的，标记义原后最终形成语义常识知识库。word representation learning(WRL)就是把词语映射到低维空间中。本文提出了三种义原编码模型来学习义原、意识、词语的表示，再结合attention机制来发现词语意识。</p><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>ono-hot:数据稀疏，忽视词语关系</p><p>提出分布式表示，所有词语投射到低维语义环境，将每个词都考虑为向量。</p><p>随着文本语料呈指数增长，模型效率很重要，所以提出的CBOW和Skip-Gram两种模型。</p><blockquote><p>这两种模型都是通过最大化词和上下文的预测概率，进一步在word affinity matrix上，利用矩阵分解来学习词表示。但没有考虑一词多义，提出一种对每个单词进行non-parametric的Skip-Gram模型。提出了用来联合学习词语、语义和近义词表示的自编码器。</p></blockquote><h3 id="Word-Sense-Disambiguation-and-Representation-learning"><a href="#Word-Sense-Disambiguation-and-Representation-learning" class="headerlink" title="Word Sense Disambiguation and Representation learning"></a>Word Sense Disambiguation and Representation learning</h3><p>WSD:在确定的上下文中计算上的识别出词语的词义和意识。</p><p>[^WSD:supervised and  kowledge-based methods]: </p><h3 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h3><p><strong>framework:SE-WRL</strong>(Sememe-Encoded WRL义原编码词语表示学习)</p><p>[^该框架为词语语义消歧和表示学习任务，考虑了义原信息。]: </p><h3 id="Knowledege"><a href="#Knowledege" class="headerlink" title="Knowledege"></a>Knowledege</h3><p><strong>Semems,Sesens and words in Hownet</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200813104751621.png" alt="image-20200813104751621"></p><p>[^第一层表示词语“苹果”，第二层表示苹果的两个语义“电脑”与”水果“。第三层表示第一个语义有三个义原“电脑、携带和特定牌子。]: </p><h3 id="Conventional-Skip-Gram-Model"><a href="#Conventional-Skip-Gram-Model" class="headerlink" title="Conventional Skip-Gram Model"></a>Conventional Skip-Gram Model</h3><p>[^义原、语义、词语集合为X,S,W]: </p><p>对于每一条纯文本序列中的目标字w，C(w)代表它的上下词语集合</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200813110339351.png" alt="image-20200813110339351"></p><h3 id="SE-WRL-model"><a href="#SE-WRL-model" class="headerlink" title="SE-WRL model"></a>SE-WRL model</h3><p>SE-WRL model的三种应用义原信息的不同策略，包括SSA,SAC,SAT.</p><h5 id="1-SSA-Simple-Sememe-Aggregation-Model-简单义原聚集模型"><a href="#1-SSA-Simple-Sememe-Aggregation-Model-简单义原聚集模型" class="headerlink" title="1.SSA(Simple Sememe Aggregation Model)简单义原聚集模型"></a>1.SSA(Simple Sememe Aggregation Model)简单义原聚集模型</h5><p>SSA把所有词语的语义的义原一同考虑进来，用目标词的所有上下文的义原嵌入的平均值来表示。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200813111950211.png" alt="image-20200813111950211"></p><h5 id="2-SAC-Sememe-Attention-over-Context-Model-基于上下文的义原注意力模型"><a href="#2-SAC-Sememe-Attention-over-Context-Model-基于上下文的义原注意力模型" class="headerlink" title="2.SAC(Sememe Attention over Context Model)基于上下文的义原注意力模型"></a>2.SAC(Sememe Attention over Context Model)基于上下文的义原注意力模型</h5><p>SSA模型用聚集的义原嵌入来代替目标词词嵌入，用义原信息编码来进行词表示学习。</p><p>但是不能处理大多数词的多义词现象。SAC利用注意力机制，根据当前词自动选择上下文合适的语义。</p><h5 id="3-SAT-Sememe-Attention-over-Target-Model-基于目标词的义原注意力模型"><a href="#3-SAT-Sememe-Attention-over-Target-Model-基于目标词的义原注意力模型" class="headerlink" title="3.SAT(Sememe Attention over Target Model)基于目标词的义原注意力模型"></a>3.SAT(Sememe Attention over Target Model)基于目标词的义原注意力模型</h5><p>与SAC模型不同，SAT为上下文词语学习原始的词嵌入，但是为目标词学习义原嵌入。</p><h3 id="Word-Similarity词汇相似度"><a href="#Word-Similarity词汇相似度" class="headerlink" title="Word Similarity词汇相似度"></a>Word Similarity词汇相似度</h3><p>通过比较在给定的数据集上，通过词语表示学习模型计算出的词对相似度来衡量词语表示的质量。词语表示学习模型在语义空间中，根据词语的距离来计算词语相似度。</p><h3 id="Word-Analogy词语类推"><a href="#Word-Analogy词语类推" class="headerlink" title="Word Analogy词语类推"></a>Word Analogy词语类推</h3><p>词语类比推理是用来评价模型词语表示学习质量的任务。</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>利用义原信息来表示每一个词各种各样的语义，提出了可以自动地上下文中选取合适的语义的义原注意力。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/fengyubo/p/9365824.html" target="_blank" rel="noopener">https://www.cnblogs.com/fengyubo/p/9365824.html</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
        <tags>
            
            <tag> Word Representation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>phrases-embedding the dictionary</title>
      <link href="/2020/08/12/phrases-embedding-the-dictionary/"/>
      <url>/2020/08/12/phrases-embedding-the-dictionary/</url>
      
        <content type="html"><![CDATA[<h3 id="Name"><a href="#Name" class="headerlink" title="Name"></a>Name</h3><p><strong>Learning to Understand Phrases by Embedding the Dictionary</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sequence-wuenda</title>
      <link href="/2020/08/01/sequence-wuenda/"/>
      <url>/2020/08/01/sequence-wuenda/</url>
      
        <content type="html"><![CDATA[<h3 id="1-2数学符号"><a href="#1-2数学符号" class="headerlink" title="1.2数学符号"></a>1.2数学符号</h3><ol><li><p>创建词表（UNK表示未知词）2.represent word(ono-hot)</p><p>[^use x&lt;1&gt;,x&lt;2&gt;,…,x<tx>,tx表示sequence length]: </tx></p></li></ol><h3 id="1-3RNN-Recurrent-Netrual-Network"><a href="#1-3RNN-Recurrent-Netrual-Network" class="headerlink" title="1.3RNN(Recurrent Netrual Network)"></a>1.3RNN(Recurrent Netrual Network)</h3><h4 id="Why-not-choose-standard-Network"><a href="#Why-not-choose-standard-Network" class="headerlink" title="Why not choose standard Network?"></a>Why not choose standard Network?</h4><p><strong>-Reason:</strong></p><ol><li>Input and output’s length is differrent.(use pad is not good)</li><li>can’t share features in the different positions of text.</li></ol><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><blockquote><p>RNN计算输出只考虑了之前的输入，没有考虑之后的输入。</p></blockquote><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200801172800273.png" alt="image-20200801172800273"></p><p>[^a&lt;0&gt;一般是空向量，Wya表示乘a类型的向量，计算出y类型的向量。]: </p><h4 id="Simplified-RNN-notation"><a href="#Simplified-RNN-notation" class="headerlink" title="Simplified RNN notation"></a>Simplified RNN notation</h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200801174401617.png" alt="image-20200801174401617"></p><h3 id="1-4通过时间的方向传播"><a href="#1-4通过时间的方向传播" class="headerlink" title="1-4通过时间的方向传播"></a>1-4通过时间的方向传播</h3><p>正相传递与反向传递（更新参数）</p><h3 id="1-5Examples-of-RNN"><a href="#1-5Examples-of-RNN" class="headerlink" title="1-5Examples of RNN"></a>1-5Examples of RNN</h3><blockquote><ol><li>one to one:标准类型</li><li>one to many：音乐分类/序列输入</li><li>many to one：情感</li><li>many to many（Tx=Ty)：NER</li><li>many to many(Tx不等于Ty)：机器翻译</li></ol></blockquote><h4 id="1-6语言模型和序列生成"><a href="#1-6语言模型和序列生成" class="headerlink" title="1-6语言模型和序列生成"></a>1-6语言模型和序列生成</h4><h4 id="Training-set-large-corpus-of-language"><a href="#Training-set-large-corpus-of-language" class="headerlink" title="Training set:large corpus of language"></a>Training set:large corpus of language</h4><p>语言模型会告诉你下一个出现的词语的概率。先将序列的词汇标记</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200801194059269.png" alt="image-20200801194059269"></p><blockquote><p>使用条件概率计算整个句子的概率。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200801194531781.png" alt="image-20200801194531781"></p></blockquote><h4 id="1-7对新序列采样"><a href="#1-7对新序列采样" class="headerlink" title="1-7对新序列采样"></a>1-7对新序列采样</h4><p>基于字符的语言模型相比于基于词汇的语言模型而言，不太能关注到文本的上下文关系，而且计算的时间也较长。</p><h3 id="1-8-Vanishing-gradientes-with-RNNs"><a href="#1-8-Vanishing-gradientes-with-RNNs" class="headerlink" title="1-8 Vanishing gradientes with RNNs"></a>1-8 Vanishing gradientes with RNNs</h3><p>RNN不擅长处理长期依赖的问题，反向传播较为困难。提出了GRU来解决这个问题</p><p><strong>GRU</strong></p><p>加入新的变量具有记忆能力，即记忆细胞，c<t>记录记忆细胞的值，GRU门记录</t></p><p>决定了哪个向量与更新记忆细胞有关。</p><p>Γu表示GRU门</p><h3 id="1-10长短期记忆"><a href="#1-10长短期记忆" class="headerlink" title="1-10长短期记忆"></a>1-10长短期记忆</h3><p>[^Γu更新门，Γf遗忘门，Γo输出门]: </p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802221536662.png" alt="image-20200802221536662"></p><h3 id="1-11双向神经网络"><a href="#1-11双向神经网络" class="headerlink" title="1-11双向神经网络"></a>1-11双向神经网络</h3><p><strong>BRNN</strong></p><p>构成无向图</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802222930856.png" alt="image-20200802222930856"></p><p>前向的激活值a&lt;3&gt;与反向的激活值共同决定y&lt;3&gt;</p><h3 id="1-12深层循环神经网络"><a href="#1-12深层循环神经网络" class="headerlink" title="1-12深层循环神经网络"></a>1-12深层循环神经网络</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802224119713.png" alt="image-20200802224119713"></p><h3 id="NLP-and-word-representation"><a href="#NLP-and-word-representation" class="headerlink" title="NLP and word representation"></a>NLP and word representation</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802230012280.png" alt="image-20200802230012280"></p><h4 id="Visualizing-word-embedding"><a href="#Visualizing-word-embedding" class="headerlink" title="Visualizing word embedding"></a>Visualizing word embedding</h4><p>降维观察</p><h4 id="使用词嵌入"><a href="#使用词嵌入" class="headerlink" title="使用词嵌入"></a>使用词嵌入</h4><p>1.在大量文本集中使用词向量表示文本（或下载预训练的嵌入模型）</p><p>2.使用one-hot表示词向量</p><p>3在含有少量标签的数据集中继续训练</p><h3 id="2-3词嵌入的特性"><a href="#2-3词嵌入的特性" class="headerlink" title="2.3词嵌入的特性"></a>2.3词嵌入的特性</h3><h4 id="Analogies-using-word-vectors"><a href="#Analogies-using-word-vectors" class="headerlink" title="Analogies using word vectors"></a>Analogies using word vectors</h4><p>t-SNE:300D-&gt;2D</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200804100405784.png" alt="image-20200804100405784"></p><p>因为women-man，king-queen相差的都是gender</p><h3 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h3><p><strong>skip-grams:</strong>抽取上下文、选择目标词</p><p>分别在上下文的一定范围内选择代表词，构造监督学习问题</p><blockquote><p>分级softmax：哈夫曼思想</p><p>上下文采样：1.根据语料库均匀随机的采样（无关词出现的频率太高）</p><p>2.使用启发式找到常出现并且含有有效信息的词</p></blockquote><h3 id="2-7负采样（Negative-sample"><a href="#2-7负采样（Negative-sample" class="headerlink" title="2.7负采样（Negative sample)"></a>2.7负采样（Negative sample)</h3><p>用content预测word,结果为1/0（正样本/负样本）</p><p>k=5-20 small data set</p><p>k=2-5 big data set(k:skip-window)</p><p>Glove算法</p><p>Xij表示i-j在上下文出现的次数</p><h3 id="sentiment-classification"><a href="#sentiment-classification" class="headerlink" title="sentiment classification"></a>sentiment classification</h3><p>情绪分类需要借助RNN来判断good和not good的区别</p><p>消除偏差时需要</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sequence model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SIGIR-2020</title>
      <link href="/2020/07/27/sigir-2020/"/>
      <url>/2020/07/27/sigir-2020/</url>
      
        <content type="html"><![CDATA[<h3 id="Prof-Zongben-Xu"><a href="#Prof-Zongben-Xu" class="headerlink" title="Prof.Zongben Xu"></a>Prof.Zongben Xu</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727152040478.png" alt="image-20200727152040478"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727152310072.png" alt="image-20200727152310072"></p><p>prerequisite</p><p>MLemail</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727181706415.png" alt="image-20200727181706415"></p><p>bert相比于Transformer+Ngram</p><p>利用上下文相邻词的搭配信息计算出具有最大概率的句子。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727181533041.png" alt="image-20200727181533041"></p><p>该表格是人为训练得到的词组附加信息</p><p>代码部分：</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802103545203.png" alt="image-20200802103545203"></p><blockquote><p>data_preprocessing:运行模型前要安装的包</p><p>LICNSE:协议</p><p>gitgnore：上传GitHub时可忽略</p><p>modles：存放模型</p><p>机器学习流程：训练（用有标记的数据训练）、测试（用有标记的数据检测正确率）、预测（没有答案，没有标记）</p></blockquote><p>huggingface/transformers   NLP模型</p><p>confi设置</p><p>modeling模型</p><p>Tokenization符号化（按词分开按字分开）</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802105517955.png" alt="image-20200802105517955"></p><p>seq2seq翻译问题序列到序列finetune后训练 预训练</p><p>run_squard预测答案的所在的区间</p><p>做任务看example</p><p>_tf</p><p>wmseq.model</p><p>InputExample:ba’yi’ge’li’zi’zhuan’hua’wie’t</p><p>Bert</p><p>BIES</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200802110057407.png" alt="image-20200802110057407"></p><p>word2id</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727183526167.png" alt="image-20200727183526167"></p><p>加载tokenazation</p><p>ymcil/Chinese-BERT-wwm#bert模型</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727183644598.png" alt="image-20200727183644598"></p><p>快速加载：只需要填词就可以</p><p>都会存在hpara</p><p>分类器只能告诉类别，不能加限制</p><p>解码器限制输出是合法输出BIE/BE，此刻输出</p><p>CRF概率模型B-F 50</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727184205047.png" alt="image-20200727184205047"></p><p>PYTORCH</p><p>forward数据流动</p><p>——init——()</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/0V~FRU9G3J4SI%7D~4%V0JGCP.png" alt="img"></p><p>forward call(tf)</p><p>![img](C:/Users/89582/Documents/Tencent Files/895824013/Image/C2C/J@QW_9L~)TBJX7F4K1Z)$D4.png)</p><p>input——id attention_mask:qkv</p><p>QKV:</p><p>Masked Self-attention:</p><p>attenton_mask：控制每个时间点看到的词语</p><p>bert</p><p>tansformer;enconder,decoder,enconder-deconder</p><p>信息流处理</p><p>模型尽可能小获取更多的信息transformer</p><p>istm模型遗忘</p><p>kv——memory</p><p>viterbi</p><p>crf参考了上一个的概率以及当前输入的-综合算出概率</p><p>概率图模型<img src="https://bkimg.cdn.bcebos.com/pic/7dd98d1001e93901e04c0c6e7cec54e736d19610?x-bce-process=image/watermark,image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5" alt="img"></p><p>神经网络的前身是概率图模型</p><p>.class Word kVMN:</p><p>。batchsize越大越好permute</p><p>matmul</p><p>clamp</p><p>exp自然范围</p><p>stack对函数</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pytorch official code</title>
      <link href="/2020/07/20/pytorch-official-code/"/>
      <url>/2020/07/20/pytorch-official-code/</url>
      
        <content type="html"><![CDATA[<h3 id="1-numpy"><a href="#1-numpy" class="headerlink" title="1.numpy"></a>1.numpy</h3><p>[^numpy提供n维数组对象，是科学计算的通用框架，不涉及图，深度学习、梯度。但可借助网络手动实现向前向后传递。]: </p><pre><code># -*- coding: utf-8 -*-import numpy as np# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random input and output datax = np.random.randn(N, D_in)y = np.random.randn(N, D_out)# Randomly initialize weightsw1 = np.random.randn(D_in, H)w2 = np.random.randn(H, D_out)learning_rate = 1e-6for t in range(500):    # Forward pass: compute predicted y    h = x.dot(w1)    h_relu = np.maximum(h, 0)    y_pred = h_relu.dot(w2)    # Compute and print loss    loss = np.square(y_pred - y).sum()    print(t, loss)    # Backprop to compute gradients of w1 and w2 with respect to loss    grad_y_pred = 2.0 * (y_pred - y)    grad_w2 = h_relu.T.dot(grad_y_pred)    grad_h_relu = grad_y_pred.dot(w2.T)    grad_h = grad_h_relu.copy()    grad_h[h &lt; 0] = 0    grad_w1 = x.T.dot(grad_h)    # Update weights    w1 -= learning_rate * grad_w1    w2 -= learning_rate * grad_w2</code></pre><p>1.1numpy.random.randn(d0,d1,…,dn)</p><blockquote><p>#rand 函数给定维度生成[0,1)之间的数据，包含0，不包含1</p><p>dn表示每个维度</p><p>返回值为维度为d0<em>d1</em>….*dn的矩阵</p></blockquote><p>1.2range(start,stop,step)函数</p><blockquote><p>start:计数开始点（默认0）</p><p>stop:技术结束点（不包括stop）</p><p>step：步长（默认1）</p></blockquote><p>1.3numpy.dot(arr1,arr2)//numpy.dot(matrix1,matrix2)</p><blockquote><p>求解两数组的内积/矩阵积</p></blockquote><p>1.4numpy.maximum(x,y)</p><blockquote><p>求x与y较大者</p></blockquote><p>1.5numpy.max(a,axis=None,out=None,keepdims=False)</p><blockquote><p>求序列的最值，最少接收一个参数，axis（=0为列向，=1为行向量）</p></blockquote><p>1.6matrix.T(m)</p><blockquote><p>求矩阵的转置</p></blockquote><p>1.7numpy.square(num)</p><blockquote><p>求num的平方</p></blockquote><h3 id="2-Tensor"><a href="#2-Tensor" class="headerlink" title="2.Tensor"></a>2.Tensor</h3><p>[^Tensor是张量，即任意维度的向量，pytorch可以利用GPU加速数字计算，要在GPU上运行pytorch Tensor，需要将其转换为新的数据类型]: </p><pre><code># -*- coding: utf-8 -*-import torchdtype = torch.floatdevice = torch.device("cpu")# device = torch.device("cuda:0") # Uncomment this to run on GPU# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random input and output datax = torch.randn(N, D_in, device=device, dtype=dtype)y = torch.randn(N, D_out, device=device, dtype=dtype)# Randomly initialize weightsw1 = torch.randn(D_in, H, device=device, dtype=dtype)w2 = torch.randn(H, D_out, device=device, dtype=dtype)learning_rate = 1e-6for t in range(500):    # Forward pass: compute predicted y    h = x.mm(w1)    h_relu = h.clamp(min=0)    y_pred = h_relu.mm(w2)    # Compute and print loss    loss = (y_pred - y).pow(2).sum().item()    if t % 100 == 99:        print(t, loss)    # Backprop to compute gradients of w1 and w2 with respect to loss    grad_y_pred = 2.0 * (y_pred - y)    grad_w2 = h_relu.t().mm(grad_y_pred)    grad_h_relu = grad_y_pred.mm(w2.t())    grad_h = grad_h_relu.clone()    grad_h[h &lt; 0] = 0    grad_w1 = x.t().mm(grad_h)    # Update weights using gradient descent    w1 -= learning_rate * grad_w1    w2 -= learning_rate * grad_w2</code></pre><p>2.1torch.device(‘cpu’/‘cuda’)</p><blockquote><p>将torch.Tensor分配到的设备的对象</p></blockquote><p>2.2torch.mm(input,mat2,out=None)</p><blockquote><p>对矩阵input和mat2执行矩阵乘法，返回结果矩阵</p></blockquote><p>2.3torch.clamp(input,min,max,out=None)-&gt;Tensor</p><blockquote><p>input:输入张量；min：限制范围下限；max：上限；out：输出张量</p></blockquote><h3 id="3-Autograd"><a href="#3-Autograd" class="headerlink" title="3.Autograd"></a>3.Autograd</h3><p>[^针对大型网络而言，手动实现前向和后向传递非常麻烦，使用autograd自动计算神经网络中的反向传递。pytorch中的autograd软件包完全提供了此功能，前向传递定义一个计算图；节点为张量，边为输入张量产生输出张量的函数，接着就可以通过该图进行反向传播，可以轻松计算梯度。if x:Tensor,x.requires_grad=True,x.grad是另一个Tensor。]: </p><blockquote><p>不需要手动通过网络实现反向传递，使用Pytorch Tensor和autograd来实现两层网络。</p></blockquote><pre><code># -*- coding: utf-8 -*-import torchdtype = torch.floatdevice = torch.device("cpu")# device = torch.device("cuda:0") # Uncomment this to run on GPU# N is batch size; D_in is input dimension;# H is hidden dimension; D_out is output dimension.N, D_in, H, D_out = 64, 1000, 100, 10# Create random Tensors to hold input and outputs.# Setting requires_grad=False indicates that we do not need to compute gradients# with respect to these Tensors during the backward pass.x = torch.randn(N, D_in, device=device, dtype=dtype)y = torch.randn(N, D_out, device=device, dtype=dtype)# Create random Tensors for weights.# Setting requires_grad=True indicates that we want to compute gradients with# respect to these Tensors during the backward pass.w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)learning_rate = 1e-6for t in range(500):    # Forward pass: compute predicted y using operations on Tensors; these    # are exactly the same operations we used to compute the forward pass using    # Tensors, but we do not need to keep references to intermediate values since    # we are not implementing the backward pass by hand.    y_pred = x.mm(w1).clamp(min=0).mm(w2)    # Compute and print loss using operations on Tensors.    # Now loss is a Tensor of shape (1,)    # loss.item() gets the scalar value held in the loss.    loss = (y_pred - y).pow(2).sum()    if t % 100 == 99:        print(t, loss.item())    # Use autograd to compute the backward pass. This call will compute the    # gradient of loss with respect to all Tensors with requires_grad=True.    # After this call w1.grad and w2.grad will be Tensors holding the gradient    # of the loss with respect to w1 and w2 respectively.    loss.backward()    # Manually update weights using gradient descent. Wrap in torch.no_grad()    # because weights have requires_grad=True, but we don't need to track this    # in autograd.    # An alternative way is to operate on weight.data and weight.grad.data.    # Recall that tensor.data gives a tensor that shares the storage with    # tensor, but doesn't track history.    # You can also use torch.optim.SGD to achieve this.    with torch.no_grad():        w1 -= learning_rate * w1.grad        w2 -= learning_rate * w2.grad        # Manually zero the gradients after updating weights        w1.grad.zero_()        w2.grad.zero_()</code></pre><p>3.1</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention is all your need</title>
      <link href="/2020/07/15/attention-is-all-your-need/"/>
      <url>/2020/07/15/attention-is-all-your-need/</url>
      
        <content type="html"><![CDATA[<h3 id="Expanding-knowledge"><a href="#Expanding-knowledge" class="headerlink" title="Expanding  knowledge"></a><strong>Expanding  knowledge</strong></h3><blockquote><p>1.RNN(Recurrent Neural Network)循环神经网络：为了能更好的处理前后相关的sequence信息提出了RNN。假设该网络在输入为xt，隐藏层为st，输出为ot，前提下，st的值不仅取决于xt，还取决于st-1</p><p>2.CNN(Conventional Neural Network)卷积神经网络</p><p>3.LSTM长短时记忆（Long Short Time Memory)：</p><p>1.处理和预测时间序列中间隔和延迟相对较长的重要事件（在词汇预测中如果关联词相差较远，RNN就会出现“梯度消失”的问题</p><p>2.三种门：遗忘门（丢弃的信息）、输入门（新加入的信息）、输出门（输出的信息）</p></blockquote><p><strong>attention机制</strong></p><p>与RNN,CNN不同，完全采用的是attention机制，具有更强的的并行性、节约了训练的时间</p><p><strong>Result</strong></p><p>Transformer模型采用的训练结果比最好结果（English-to-French modle)中提升了两个蓝度。</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>基础是Extended Neural GPU,ByteNet,ConvS2S,它们中两个词汇之间的依赖关系与两者之间的距离反相关，这样如果两个词汇的距离太远它们的依赖性就很难体现。Transformer模型针对这种缺陷提出了Multi-Head Attention，Transformer模型没有使用RNN,CNN，它全部使用了attention机制对整个机制进行监控。</p><h3 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200716234419464.png" alt="image-20200716234419464"></p><blockquote><p><strong>basic knowledge</strong></p><ol><li><p>Embedding：引用one-hot方法词向量会很高维而且稀疏，使用Emedding更能找出词向量的相似性，这样就可以进行降维操作。计算嵌入矩阵前首先确定潜在因子，将个别单词用潜在因子组成的向量进行表示，其他单词可以用矩阵中向量的索引表示，探索具有相似性的词语，利用降维技术对词语进行相似性可视化。</p></li><li><p>positional encoding</p><p>对位置不敏感的模型（模型的输出不随着文本数据顺序的改变而改变）分为两类，Sinusoidal Positional Encoding（相对）和Learned Positional Encoding.（绝对）</p><p>[^绝对是对不同位置随机初始化一个position embedding,相对位置向量：用正余弦函数分别表示绝对位置，然后用乘积表示绝对位置，complex embedding使用复数域上连续函数来编码词在不同位置的表示。]: </p></li></ol></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep-learning </tag>
            
            <tag> language model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MRC for NER</title>
      <link href="/2020/07/10/mrc-for-ner/"/>
      <url>/2020/07/10/mrc-for-ner/</url>
      
        <content type="html"><![CDATA[<h2 id="A-Unified-MRC-Framework-for-Named-Entity-Recognition"><a href="#A-Unified-MRC-Framework-for-Named-Entity-Recognition" class="headerlink" title="A Unified MRC Framework for Named Entity Recognition"></a>A Unified MRC Framework for Named Entity Recognition</h2><blockquote><p><strong>Abstract:</strong>The task of named entity recognition (NER) is normally divided into nested NER and flat NER depending on whether named entities are nested or not. Models are usually separately developed for the two tasks, since sequence labeling models are only able to assign a single label to a particular token, which is unsuitable<br>fornested NER where a token may be assigned several labels.</p></blockquote><h3 id="concepts"><a href="#concepts" class="headerlink" title="concepts"></a>concepts</h3><ul><li><p>实体重叠</p><p>可能会出现实体重叠的问题，即一个句子“席慕容散文集是我最喜欢的书”。在这个句子中“席慕容”和“席慕容散文集”都是实体，并且有重叠的部分。但传统做法无法解决此类问题，因为一个token只属于一个tag。</p></li></ul><p><strong>Qusetion</strong></p><p>​        本文针对实体重叠问题提出了一种统一的框架，可以分别处理falt and nested NER task.</p><p><strong>Strategy</strong></p><p>​        与传统的序列标记问题不同的是，作者采用了MRC（machine reading comprehension)来进行任务完成。即提取两个实体需要提问两次得到答案。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> PaperLookThrough </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -NER -实体重叠 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>deep learning-Wuenda</title>
      <link href="/2020/07/07/deep-learning-wuenda/"/>
      <url>/2020/07/07/deep-learning-wuenda/</url>
      
        <content type="html"><![CDATA[<h3 id="4-1多功能"><a href="#4-1多功能" class="headerlink" title="4-1多功能"></a>4-1多功能</h3><h3 id=""><a href="#" class="headerlink" title=""></a><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200709194136749.png" alt=""></h3><p><strong>note</strong></p><ul><li><p>n=number of features</p></li><li><p>x(i)=input of ith training example</p></li><li><p>x(i)j=value of j feature in ith training example</p><p><strong>假设函数</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200709195313024.png" alt=""></p><p>[^默认x0=1]: </p></li></ul><p>  <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200709200300679.png" alt=""></p><p>特征缩放</p><p>​        -多个特征值所在的范围都在相近的范围内，此时梯度下降算法就会更快地收敛，特征值在-1/3-1/3之间较好，过大过小都不好</p><p><strong>均值归一化</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200709201212057.png" alt=""></p><p>代价函数：<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200724215558011.png" alt=""></p><h3 id="4-5多项式回归"><a href="#4-5多项式回归" class="headerlink" title="4-5多项式回归"></a><strong>4-5多项式回归</strong></h3><p>在多个参数的代价函数中，要分别对各个参数求偏导，分别设为零。</p><p>if 斯塔为实数而非向量，那么转化为二次函数的求最值</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200724215748186.png" alt=""></p><h6 id="Gradient-Descent-vs-Normal-Equation"><a href="#Gradient-Descent-vs-Normal-Equation" class="headerlink" title="Gradient Descent vs Normal Equation"></a><strong>Gradient Descent vs Normal Equation</strong></h6><p>Gradient Descent需要不断修正学习率α，需要迭代，在n（特征量的数量）很大的情况下也能很好的工作。</p><p>Normal Equation不需要修正学习率，需要计算XtX,在n很大的情况下时间复杂度为n³，费时</p><blockquote><p>如果矩阵不可逆（singular/degenerate)，使用pinv（X’<em>X)</em>X’*Y也可求出矩阵的逆</p><p>也可以使用正则化或者删除一些特征向量</p></blockquote><p><strong>overfitting</strong>(高方差)：模型过多数据集过少</p><p>泛化能力：训练得到的模型适应新训练集的能力。</p><p>出现过拟合解决的方法：</p><ul><li><p>Reduce number of features.</p><p> -保留舍弃</p><p> -选择适当的模型（model  selection algorithm)</p></li><li><p>正则化(Regulation)</p><p>-线性回归的正则化</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200711173321699.png" alt=""></p></li></ul><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200711175549803.png" alt=""></p><p>​            <img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200711175628518.png" alt=""></p><p>[^if X不可逆则选用prinv函数]: </p><p>​        -logistic回归的正则化</p><p>​        多项式的参数的代价函数，会导致模型过于复杂，出现过拟合</p><p>​            对各个参数分别求偏导</p><h3 id="8-1神经网络（Neural-Network"><a href="#8-1神经网络（Neural-Network" class="headerlink" title="8-1神经网络（Neural Network)"></a>8-1神经网络（Neural Network)</h3><h5 id="p43-8-1"><a href="#p43-8-1" class="headerlink" title="p43 8-1"></a><strong>p43 8-1</strong></h5><p>非线性回归</p><p>n过大时计算量过大</p><p>神经元与大脑</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200711184448515.png" alt=""></p><p>[^上标表示与第几层有关，下标表示与第几个神经元有关]: </p><p>神经元层分为三个：输入层、隐藏层（好多层）、输出层</p><p>XOR：异或：不同为一</p><p>NXOR：同或:相同为一</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200713160945825.png" alt=""></p><p>（NOT x1)AND(NOT x2)</p><p>可能有很多隐藏层</p><p>每层对输入进行不同的处理，最后送入输出层</p><p>多元分类</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200713162834051.png" alt=""></p><p>L表示层数</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200713163115839.png" alt=""></p><p>[^h\theta(x)是k维向量，(h\theta(x))$i_d$表示神经网络输出向量的第i个元素]: </p><p><strong>Gradient computation</strong></p><p>1.前向传播</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200713164907850.png" alt=""></p><p>[^a(1)为第一层的激活值，g为sigmod激活函数，计算第二层的激活函数]: </p><hr><p><strong>Backporpagation algorithm</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200719182147968.png" alt=""></p><p>反向传播就是反过来计算误差值</p><p>总结神经网络</p><p><strong>1.确定架构</strong></p><p>就是选择神经元之间的连接方法</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200719212007267.png" alt=""></p><p><strong>2.训练神经网络</strong></p><ul><li>确定初始化权值</li><li>使用正向传播算法为每个x（i）计算出h(x(i))</li><li>使用代码计算出代价J（Θ）</li><li>使用反向传播计算出每个偏导数</li><li>使用梯度检测确定反向传播计算的偏导数和用数值计算的估计值之间的误差，最后确定算法是正确的</li></ul><p>使用最优化算法来确定代价函数的最小值</p><h4 id="梯度代价函数"><a href="#梯度代价函数" class="headerlink" title="梯度代价函数"></a><strong>梯度代价函数</strong></h4><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200720084214076.png" alt=""></p><p>通过求偏导数无限接近于代价较小的点</p><h3 id="10-2评估假设"><a href="#10-2评估假设" class="headerlink" title="10-2评估假设"></a>10-2评估假设</h3><p>将数据集70%用于训练集，30%用于测试集。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200720084824398.png" alt=""></p><h4 id="Model-Selection"><a href="#Model-Selection" class="headerlink" title="Model Selection"></a><strong>Model Selection</strong></h4><p><strong>Evaluating your hypothesis</strong></p><p>6:2:2(训练集：交叉验证集：测试集)</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200720090804228.png" alt=""></p><p><strong>Model selection</strong></p><p>用验证集或者交叉验证集来选择模型，评估泛化误差（防止过拟合）</p><p>ps：与前面的验证集不同，前面的验证集只能选择合适的模型，无法评估泛化能力。</p><p><strong>10-4偏差与方差</strong>（欠拟合与过拟合）</p><blockquote><p>偏差：预测值的期望与真实值之间的差距，偏差越大，越偏离真实数据</p><p>方差：描述预测值的变化范围，离散程度</p></blockquote><p>训练集和交叉验证集的代价计算公式</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200721103256057.png" alt=""></p><p>两种误差的变化趋势</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200721103150199.png" alt=""></p><p><strong>10-5结合正则化</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200721103958207.png" alt=""></p><p>选择使代价最小的λ值</p><h3 id="10-6学习曲线"><a href="#10-6学习曲线" class="headerlink" title="10-6学习曲线"></a>10-6学习曲线</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200721113346897.png" alt=""></p><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200721162202446.png" alt=""></p><h3 id="11-1确定执行的优先级"><a href="#11-1确定执行的优先级" class="headerlink" title="11-1确定执行的优先级"></a>11-1确定执行的优先级</h3><p><strong>example</strong>：垃圾邮件分类器</p><h3 id="11-2误差分析"><a href="#11-2误差分析" class="headerlink" title="11-2误差分析"></a>11-2误差分析</h3><blockquote><ol><li>建立一个简单的模型</li><li>画出学习曲线以及分析</li><li>误差分析（找出需要特殊处理的样本）在交叉验证集上进行</li></ol></blockquote><h3 id="11-3不对称分类的误差分析"><a href="#11-3不对称分类的误差分析" class="headerlink" title="11-3不对称分类的误差分析"></a>11-3不对称分类的误差分析</h3><p>Cancer classification example</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200721223025519.png" alt=""></p><p>precision表示交叉部分占所有预测值的比例</p><p>recall表示交叉部分占总的正例的比例</p><h3 id="11-5机器学习数据"><a href="#11-5机器学习数据" class="headerlink" title="11-5机器学习数据"></a>11-5机器学习数据</h3><h3 id="12-1优化数据"><a href="#12-1优化数据" class="headerlink" title="12-1优化数据"></a>12-1优化数据</h3><h4 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h4><ol><li><p>logistic回归</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200722153941516.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200722154423535.png" alt=""></p></li></ol><blockquote><p>SVM：Support Vector Machine,向量机：用supervised learning对数据进行二元分类的广义分类器</p></blockquote><h4 id="12-3大间隔分类器"><a href="#12-3大间隔分类器" class="headerlink" title="12-3大间隔分类器"></a>12-3大间隔分类器</h4><blockquote><p><strong>向量内积</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200722161211108.png" alt="">        </p></blockquote><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200723113904597.png" alt=""></p><p>为了达到向量机优化算法的目的，要使参数θ的取值范围尽可能小，为了保持p*θ&gt;=1（正样本）恒成立，p的取值应该尽可能大，p为样本点在向量参数θ上的投影，显然右图的投影长度更长。（即正负样本与分类线之间的距离更大）</p><h3 id="12-核函数"><a href="#12-核函数" class="headerlink" title="12-*核函数"></a>12-*核函数</h3><h5 id="非线性函数的决策边界"><a href="#非线性函数的决策边界" class="headerlink" title="非线性函数的决策边界"></a>非线性函数的决策边界</h5><p>[^要确定计算边界要构造一个很复杂的多项式函数θ，但是过于复杂，就提出核函数]: </p><p><strong>高斯核函数</strong></p><p>[^||x-l(1)||是欧式距离]: </p><p>1.选择标记点</p><p>2.用高斯核函数计算f值</p><p>3.代入预测函数计算结果是1or0</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200723163128297.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200723162655307.png" alt=""></p><p>** how to choose landmarks**：直接将训练样本点的位置作为标记点的位置</p><p>计算fi=similarity(x,l^i)</p><p><strong>SVM parameters</strong></p><h5 id="SVM应用"><a href="#SVM应用" class="headerlink" title="*SVM应用 *"></a><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200723214650858.png" alt="">*<em>SVM应用 *</em></h5><p>1.选择内核参数C和内核</p><p>[^没有内核就是线性内函数，通过计算参数不等式来确定取值]: </p><h3 id="13-1无监督学习"><a href="#13-1无监督学习" class="headerlink" title="13-1无监督学习"></a>13-1无监督学习</h3><blockquote><p>提出聚类算法-分类无标签的数据集</p></blockquote><h3 id="13-2K-means算法"><a href="#13-2K-means算法" class="headerlink" title="13-2K-means算法"></a>13-2K-means算法</h3><p><strong>cluster assignment</strong></p><ol><li>簇分配：随机生成两个聚类中心</li><li>根据距离聚类中心更近的原则进行分类</li><li>移动聚类中心：计算所有红类点的坐标均值，将聚类中心移动到该点上，继续进行2操作直至聚类中心不在移动</li></ol><p><strong>non-separated clusters</strong></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.bilibili.com/video/BV164411b7dx?p=76" target="_blank" rel="noopener">https://www.bilibili.com/video/BV164411b7dx?p=76</a></p><h3 id="13-3优化函数"><a href="#13-3优化函数" class="headerlink" title="13-3优化函数"></a>13-3优化函数</h3><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727092604110.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727092711287.png" alt=""></p><h3 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h3><p>为了避局部最优化，初始选择多次局部最优化。具体过程如下：</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727093439675.png" alt=""></p><h3 id="13-5选择聚类数量"><a href="#13-5选择聚类数量" class="headerlink" title="13-5选择聚类数量"></a>13-5选择聚类数量</h3><p>[^最常见就是手动选择。需要结合自己的经验，还可以借助]: </p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727094948688.png" alt=""></p><h3 id="14-1目标Ⅰ：数据压缩"><a href="#14-1目标Ⅰ：数据压缩" class="headerlink" title="14-1目标Ⅰ：数据压缩"></a>14-1目标Ⅰ：数据压缩</h3><blockquote><p>节省内存或者硬盘空间，加快算法计算速度。</p></blockquote><p><strong>Data Compreesion</strong></p><p>降维可以使用投影的方法</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727100241361.png" alt=""></p><h3 id="14-2目标Ⅱ：可视化数据"><a href="#14-2目标Ⅱ：可视化数据" class="headerlink" title="14-2目标Ⅱ：可视化数据"></a>14-2目标Ⅱ：可视化数据</h3><p><strong>Data Visualization</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727100835002.png" alt=""></p><p><strong>Reduce 50D to 2D</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727100913558.png" alt=""></p><h3 id="14-3-4主成分分析问题规划（PCA"><a href="#14-3-4主成分分析问题规划（PCA" class="headerlink" title="14-3-4主成分分析问题规划（PCA)"></a>14-3-4主成分分析问题规划（PCA)</h3><p>[^PCA：寻找一个低维平面，使得数据投影在直线上的垂直距离平方和达到最小值。如下图所示，如果选择品红色的直线而非大红色的直线，如果选择品红色直线，数据点需要移动很长的距离才能到达投影直线。]: </p><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200727104627377.png" alt="image-20200727104627377"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727105537284.png" alt="image-20200727105537284"></p><p>PCA选择计算的是垂直距离，linear regression选择的是与直线的正交距离</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727155808024.png" alt="image-20200727155808024"></p><p>[^svd：奇异值分解]: </p><p>$$<br>[U,S,V] = svd(Sigma)</p><p>sigma is a n*n matrix.<br>$$</p><p>取U矩阵的前k列，与矩阵X相乘得到矩阵Z</p><h4 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200727160229473.png" alt="image-20200727160229473"></h4><h3 id="14-5主成分数量选择"><a href="#14-5主成分数量选择" class="headerlink" title="14-5主成分数量选择"></a>14-5主成分数量选择</h3><p><strong>choose k(number of principal components</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deep-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MNER-Multimodal Entity Span Detection</title>
      <link href="/2020/07/06/improving-multimodal-named-entity-recognition-via-entity-spandetection-with-unified-multimodal-transformer/"/>
      <url>/2020/07/06/improving-multimodal-named-entity-recognition-via-entity-spandetection-with-unified-multimodal-transformer/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Named-entity recognition</strong> (NER) (also known as <strong>entity identification</strong>, <strong>entity chunking</strong> and <strong>entity extraction</strong>) is a subtask of <a href="https://encyclopedia.thefreedictionary.com/Information+extraction" target="_blank" rel="noopener">information extraction</a> that seeks to locate and classify named entities in text into pre-defined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc.</p></blockquote><h4 id="A-example-of-NER"><a href="#A-example-of-NER" class="headerlink" title="A example of NER:"></a>A example of NER:</h4><table><thead><tr><th>Jim bought 300 shares of Acme Corp. in 2006.</th></tr></thead><tbody><tr><td>[Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time.</td></tr></tbody></table><p><strong>level</strong>:ACL2020</p><p><strong>author:</strong>Jianfei Yu</p><p><strong>keywords:</strong>MNER,Entity Span Detection</p><h2 id="Qusetions"><a href="#Qusetions" class="headerlink" title="##Qusetions"></a>##Qusetions</h2><blockquote><h3 id="MNER-drawbacks"><a href="#MNER-drawbacks" class="headerlink" title="MNER drawbacks"></a>MNER drawbacks</h3></blockquote><ul><li><p>the words are insensitive to the visual context</p><p>现有的方法侧重模态间交互进行建模，因为单词的隐藏层表示仍然基于文本上下文，对视觉上下文不敏感。</p><p>忽略了合并视觉信息的误差。关联的图片信息只包括句子中的一两个实体，不涉及其他实体，这样会使其他实体无法识别。</p></li><li><p>most of the words ignore the bias brought by the visual context</p></li></ul><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="Strategy"><a href="#Strategy" class="headerlink" title="Strategy:"></a>Strategy:</h3><p>1.main strategy:多通道交互模块（MMI）：standard Transformer layer+cross-model attention mechanism</p><p>2.auxiliary task:leverage purely text-based entity span detection</p><p>Consequence:</p><p>achieves the new state-of-the-artperformance on two benchmark datasets.</p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p> Overall Architecture of Our Unified Multimodal Transformer.</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200708184644333.png" alt="image-20200708184644333"></p><h3 id="Transformer模型"><a href="#Transformer模型" class="headerlink" title="Transformer模型"></a>Transformer模型</h3><h5 id="采用encoder-decoder模型。与Attention相似"><a href="#采用encoder-decoder模型。与Attention相似" class="headerlink" title="采用encoder-decoder模型。与Attention相似"></a>采用encoder-decoder模型。与Attention相似</h5><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200708094459080.png" alt="image-20200708094459080"></p><p><strong>基本内部结构</strong>如图所示，进入Encoder层前先将单词进行Emebedding操作，self-attention操作后送入前馈神经网络，也可并行进行self-attention和前馈神经网络。</p><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200708095052382.png" alt="image-20200708095052382"></p><h4 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a><strong>BERT</strong></h4><ul><li><p>全称Bidirectional Encoder Representation from Transformers，即双向Transformer的Encoder</p></li><li><p><strong>创新点：</strong>pre-train：Masked LM+Next Sentence Prediction</p><p><strong>MLM（Masked LM)</strong>可以理解为完形填空，作者会随机mask每一个句子中15%的词，用其上下文来做预测，例如：<code>my dog is hairy → my dog is [MASK]</code></p><p>此处将hairy进行了mask处理，然后采用非监督学习的方法预测mask位置的词是什么，但是该方法有一个问题，因为是mask15%的词，其数量已经很高了，这样就会导致某些词在fine-tuning阶段从未见过，为了解决这个问题，作者做了如下的处理：</p><ul><li>80%的时间是采用[mask]，my dog is hairy → my dog is [MASK]</li><li>10%的时间是随机取一个词来代替mask的词，my dog is hairy -&gt; my dog is apple</li><li>10%的时间保持不变，my dog is hairy -&gt; my dog is hairy</li></ul><p>那么为啥要以一定的概率使用随机词呢？这是因为transformer要保持对每个输入token分布式的表征，否则Transformer很可能会记住这个[MASK]就是”hairy”。至于使用随机词带来的负面影响，文章中解释说,所有其他的token(即非”hairy”的token)共享15%*10% = 1.5%的概率，其影响是可以忽略不计的。Transformer全局的可视，又增加了信息的获取，但是不让模型获取全量信息。<br>注意：</p><ul><li>有参数dupe_factor决定数据duplicate的次数。</li><li>其中，create_instance_from_document函数，是构造了一个sentence-pair的样本。对每一句，先生成[CLS]+A+[SEP]+B+[SEP]，有长（0.9）有短（0.1），再加上mask，然后做成样本类object。</li><li>create_masked_lm_predictions函数返回的tokens是已经被遮挡词替换之后的tokens</li><li>masked_lm_labels则是遮挡词对应位置真实的label。</li></ul><h4 id="Next-Sentence-Prediction"><a href="#Next-Sentence-Prediction" class="headerlink" title="Next Sentence Prediction"></a>Next Sentence Prediction</h4><p>选择一些句子对A与B，其中50%的数据B是A的下一条句子，剩余50%的数据B是语料库中随机选择的，学习其中的相关性，添加这样的预训练的目的是目前很多NLP的任务比如QA和NLI都需要理解两个句子之间的关系，从而能让预训练的模型更好的适应这样的任务。<br>个人理解：</p><ul><li>Bert先是用Mask来提高视野范围的信息获取量，增加duplicate再随机Mask，这样跟RNN类方法依次训练预测没什么区别了除了mask不同位置外；</li><li>全局视野极大地降低了学习的难度，然后再用A+B/C来作为样本，这样每条样本都有50%的概率看到一半左右的噪声；</li><li>但直接学习Mask A+B/C是没法学习的，因为不知道哪些是噪声，所以又加上next_sentence预测任务，与MLM同时进行训练，这样用next来辅助模型对噪声/非噪声的辨识，用MLM来完成语义的大部分的学习。</li></ul></li></ul><h4 id="positional-Encoding"><a href="#positional-Encoding" class="headerlink" title="positional Encoding"></a><strong>positional Encoding</strong></h4><p>Transformer中缺少一种解释单词顺序的方法，positional Encoding维度和embedding一样，可以通过它计算出任意两个词之间的距离，最终将它和Embedding相加输入下一层即可</p><h4 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a><strong>self-attention</strong></h4><ol><li>定义三个向量：Query,Key,Value(三个矩阵是embedding向量与三个随机矩阵相乘的结果，eg：维度（64，128)，注意第二个维度与embedding向量的维度相同</li><li>scores=Q*K将结果除以1提到的第一个维度的开方得到的是softmax</li></ol><p>该词代表的是每个词对于当前位置的词的相关性大小。将value和softmax相乘得到的各个结果进行相加得到的结果即为self-attention在当前节点的值</p><p><strong>Resnet</strong></p><p>​    ResNet是一种残差网络,网络越深，获取的信息越多，特征也越丰富。但是根据实验表明，随着网络的加深，优化效果反而越差，测试数据和训练数据的准确率反而降低了。这是由于网络的加深会造成梯度爆炸和梯度消失的问题。</p><p><img src="C:/Users/89582/AppData/Roaming/Typora/typora-user-images/image-20200709111035572.png" alt="image-20200709111035572"></p><p>​                                                           Multimodal Interaction (MMI) Module.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> PaperLookThrough </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MNER </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PPT Useful Plugin</title>
      <link href="/2020/05/11/ruan-jian-gong-ju/ppt/ppt-useful-plugin/"/>
      <url>/2020/05/11/ruan-jian-gong-ju/ppt/ppt-useful-plugin/</url>
      
        <content type="html"><![CDATA[<h2 id="1、PPT美化大师"><a href="#1、PPT美化大师" class="headerlink" title="1、PPT美化大师"></a>1、<a href="http://meihua.docer.com/" target="_blank" rel="noopener">PPT美化大师</a></h2><p>“让制作专业精美PPT变得简单”“让不会做PPT的人，也能做好PPT”作为一款由wps的开发公司金山软件开发的PPT插件，自然来头不小，也不负大师之名。</p><h3 id="1-1、内容规划-生成模板"><a href="#1-1、内容规划-生成模板" class="headerlink" title="1.1、内容规划 生成模板"></a>1.1、内容规划 生成模板</h3><p>在美化大师工具栏选择新建一个PPT，选择美化大师中的“<font color="red">内容规划</font>”，输入PPT所需的大标题和一二级目录标题，并选择相应合适的“风格”，即可自动生成一份PPT模板。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092132264.png" alt=""></p><p>对模板背景不满意，还可以对其进行更换，选择自己喜欢的模板。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092147169.png" alt=""></p><h3 id="1-2、模板在线选择"><a href="#1-2、模板在线选择" class="headerlink" title="1.2、模板在线选择"></a>1.2、模板在线选择</h3><p>在美化大师工具栏下选择<font color="red">资源广场</font>，里面有海量免费和收费的高质量PPT模板，可以在线购买，直接导入PPT，类似于wps的在线模板</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092201791.png" alt=""></p><h3 id="1-3、图片、图形、幻灯片素材"><a href="#1-3、图片、图形、幻灯片素材" class="headerlink" title="1.3、图片、图形、幻灯片素材"></a>1.3、图片、图形、幻灯片素材</h3><p>还在为找不好看的图片发愁么，美化大师里面提供大量各行各业的图片素材，而且几乎都是没有背景的，可以一键运用</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092216002.png" alt=""></p><h3 id="1-4、导出各类格式（拼图、全图、图片、视频）"><a href="#1-4、导出各类格式（拼图、全图、图片、视频）" class="headerlink" title="1.4、导出各类格式（拼图、全图、图片、视频）"></a>1.4、导出各类格式（拼图、全图、图片、视频）</h3><p>美化大师提供PPT拼图，可以讲PPT以拼图形式直接呈现出来，一目了然。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092234474.png" alt=""></p><h3 id="1-5、批量删除（动画、切换页-备注）"><a href="#1-5、批量删除（动画、切换页-备注）" class="headerlink" title="1.5、批量删除（动画、切换页 备注）"></a>1.5、批量删除（动画、切换页 备注）</h3><p>当我们制作了一份PPT，里面有动画但是临时有演示要求说不需要动画，我们就可以这样一件删除所有动画，另外，还可以删除所有页切换或者备注</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092248221.png" alt=""></p><h3 id="1-6、收藏喜欢的幻灯片、图形、图片"><a href="#1-6、收藏喜欢的幻灯片、图形、图片" class="headerlink" title="1.6、收藏喜欢的幻灯片、图形、图片"></a>1.6、收藏喜欢的幻灯片、图形、图片</h3><p>网上下载了一份很漂亮的PPT模板，里面有些好看的图标素材、图片素材、或者幻灯片想要保存以便日后再用，美化大师提供了在线收藏的功能，对他们进行收藏，就不用保存到自己电脑本地要用时还得找好久或者误删了。</p><h2 id="2、onekey（OK）插件"><a href="#2、onekey（OK）插件" class="headerlink" title="2、onekey（OK）插件"></a>2、onekey（OK）插件</h2><p>onekey是由一位大师@只为设计开发完成的（收下我的小膝盖），从只有简单的几个功能，发展到现在已经有一百四五十个功能。功能涵盖形状、调色、图片、演示、辅助等方面。在图片形状处理方面尤为突出，这里主要为大家简单介绍一下，更多强大到可怕的功能，官方有详细的教程需要大家自己摸索了，</p><h3 id="2-1、一键转图"><a href="#2-1、一键转图" class="headerlink" title="2.1、一键转图"></a>2.1、一键转图</h3><p>OK插件的一键转图功能非常方便实用，如果我们要讲一个做好的图表、不能嵌入PPT的字体、形状组合、处理过的图片转成一张图片，通常的操作是保存到电脑为图片再插入，过程较为繁琐，有了这个功能，可以在PPT里面原位直接转为图片，方便实用。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092325222.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092338325.png" alt=""></p><h3 id="2-2、强大的图片处理"><a href="#2-2、强大的图片处理" class="headerlink" title="2.2、强大的图片处理"></a>2.2、强大的图片处理</h3><p>ok插件强大的图片处理功能好用到爆，提供了正片叠底、滤色、柔光、反相，图片色相、图片马赛克、图片分割、形状吸附到路径、形状取图片像素、多页统一、特殊选中等等功能。例：一键虚化、一键马赛克</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092354557.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092410789.png" alt=""></p><h3 id="2-3、强大的形状处理"><a href="#2-3、强大的形状处理" class="headerlink" title="2.3、强大的形状处理"></a>2.3、强大的形状处理</h3><p>OK插件提供了强大的形状处理功能，覆盖导入、去除、复制、文本等等，例如可以导入EMF(一种PPT支持的矢量图片文件格式，在PPT中可以通过取消组合来得到矢量形状)、一键拆分段落</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092430143.png" alt=""></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092442500.png" alt=""></p><p>另外，OK插件还有颜色处理、三维处理等高大上功能，总之，OK插件是一款非常强大的PPT插件，官方也出了很多相关教程，是一款非常专业好用的PPT神器。</p><h2 id="3、口袋动画PA"><a href="#3、口袋动画PA" class="headerlink" title="3、口袋动画PA"></a>3、<a href="http://www.papocket.com/" target="_blank" rel="noopener">口袋动画PA</a></h2><p>口袋动画(Pocket Animation,简称PA)是由大安工作室(作者:安少)独立开发出来的一款PowerPoint动画插件，顾名思义就是简化PPT动画设计过程、完善PPT动画相关功能。下面举例介绍几种常用功能</p><h3 id="3-1、动画删除"><a href="#3-1、动画删除" class="headerlink" title="3.1、动画删除"></a>3.1、动画删除</h3><p>PA插件可以一键去除对象动画、幻灯片动画、整个PPT文档动画，这对于做了很多动画后领导临时要求全部删除动画的人是福音，简直节省效率神器</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092458078.png" alt=""></p><h3 id="3-2、动画序列"><a href="#3-2、动画序列" class="headerlink" title="3.2、动画序列"></a>3.2、动画序列</h3><p>对于经常要设置相同动画序列来说，这个功能超级实用，例如可以批量设置动画延迟时间，包括固定延迟、随机延迟、公式延迟等，再也不用一个一个区重复操作了。快速制作动画，就试试PA插件的这个功能吧</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092515964.png" alt=""></p><h3 id="3-3、颜色替换"><a href="#3-3、颜色替换" class="headerlink" title="3.3、颜色替换"></a>3.3、颜色替换</h3><p>PA的颜色替换功能可谓是十足的福利啊，可以将整个PPT的颜色由一种全部替换为另外一种，一键更改PPT的配色，简单又实用，无论是表格、图表，还是文本线条，它都能一键更改，再也不用一个一个改配色了，有它足以。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092530555.png" alt=""></p><h3 id="3-4、动画库"><a href="#3-4、动画库" class="headerlink" title="3.4、动画库"></a>3.4、动画库</h3><p>PA提供了一些大神为我们预先设计好的动画效果，我们可以在制作PPT的时候随时调用，省去了大量制作动画的时间。对于喜欢PPT动画的人来说，PA插件绝对是一款好用的神器。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092545705.png" alt=""></p><h3 id="3-5、高级动画设计"><a href="#3-5、高级动画设计" class="headerlink" title="3.5、高级动画设计"></a>3.5、高级动画设计</h3><p>PA动画为我们的PPT动画设计带来了更多设计灵感和想象空间，它提供了众多强大的动画设计功能，简化了PPT的动画制作流程，提供了更多原有PPT很难做到的动画功能，使我们的动画制作出来更快、更和谐。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092559627.png" alt=""></p><h2 id="4、-iSlide"><a href="#4、-iSlide" class="headerlink" title="4、 iSlide"></a>4、 <a href="https://www.islide.cc/download" target="_blank" rel="noopener">iSlide</a></h2><p>iSlide是升级版的Nordri Tools，在Nordri Tools原来的工具属性功能外，增加了更多的素材，下面是iSlide的功能一栏，只能也只做简单介绍</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092617634.png" alt=""></p><h3 id="4-1、-一键优化"><a href="#4-1、-一键优化" class="headerlink" title="4.1、 一键优化"></a>4.1、 一键优化</h3><p>iSlide也提供了一键优化的功能，包括统一字体和统一段落，为设计提供了便捷快速的操作。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092639364.png" alt=""></p><h3 id="4-2、-素材资源"><a href="#4-2、-素材资源" class="headerlink" title="4.2、 素材资源"></a>4.2、 素材资源</h3><p>iSlide相对于Nordri Tools最大的特点就是增加了大量的素材资源，包括图标库、色彩库、图示库、以及智能图表。</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092708595.png" alt=""></p><h3 id="4-3、智能图表"><a href="#4-3、智能图表" class="headerlink" title="4.3、智能图表"></a>4.3、智能图表</h3><p>在这里要为大家重要讲解一下智能图表功能。iSlide提供了众多可视化的图表，更强大的事这些图表可以自由编辑和调整，数值颜色图标等都可以编辑替换。厉害了我的智能图表。<img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200514092804307.png" alt=""></p><p><strong>转载</strong>：<a href="https://www.jianshu.com/p/c986f4b09b93" target="_blank" rel="noopener">https://www.jianshu.com/p/c986f4b09b93</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PPT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Window CommandLine</title>
      <link href="/2020/04/27/ruan-jian-gong-ju/window/window-commandline/"/>
      <url>/2020/04/27/ruan-jian-gong-ju/window/window-commandline/</url>
      
        <content type="html"><![CDATA[<h2 id="1-PowerShell"><a href="#1-PowerShell" class="headerlink" title="1. PowerShell"></a>1. PowerShell</h2><pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true">#  查看powershell 版本</span><span class="token function">get-host</span><span class="token variable">$host</span><span class="token punctuation">.</span>version<span class="token comment" spellcheck="true">#  新建目录</span><span class="token comment" spellcheck="true">#当前目录新建文件</span><span class="token function">new-item</span> FILENAME<span class="token punctuation">.</span>xxx <span class="token operator">-</span><span class="token function">type</span> file<span class="token comment" spellcheck="true">#当前目录新建文件夹</span><span class="token function">new-item</span> DIRECTORYNAME <span class="token operator">-</span><span class="token function">type</span> directory<span class="token comment" spellcheck="true">#在指定目录新建</span><span class="token function">new-item</span> TARGETDIR FILENAME<span class="token punctuation">.</span>xxx <span class="token operator">-</span><span class="token function">type</span> file<span class="token comment" spellcheck="true">#  重命名</span><span class="token comment" spellcheck="true">#把 C:/Scripts/Test.txt 重命名为 C:/Scripts/New_Name.txt:</span><span class="token function">Rename-Item</span> c:<span class="token operator">/</span>scripts<span class="token operator">/</span>Test<span class="token punctuation">.</span>txt new_name<span class="token punctuation">.</span>txt<span class="token comment" spellcheck="true">#  移动文件</span><span class="token function">Move-Item</span> c:\scripts\test<span class="token punctuation">.</span>zip c:\testX<span class="token comment" spellcheck="true">#  删除目录/文件</span><span class="token function">remove-item</span> file<span class="token comment" spellcheck="true">#显示文本内容</span><span class="token function">get-content</span> 1<span class="token punctuation">.</span>txt<span class="token comment" spellcheck="true">#罗列系统驱动器</span>get<span class="token operator">-</span>psdriver<span class="token comment" spellcheck="true">#下载文件</span>powershell <span class="token operator">-</span>Command <span class="token string">"(New-Object Net.WebClient).DownloadFile('https://ts', './src/ts')"</span><span class="token comment" spellcheck="true">#支持linux 文件  ls，dir，pwd，cat, more</span><span class="token comment" spellcheck="true"># 中文输出乱码</span>打开控制面板 <span class="token operator">-</span>> Change date<span class="token punctuation">,</span>time<span class="token punctuation">,</span>or number <span class="token operator">-</span>> 打开 “Region” 对话框选择 Administrative 选项卡，点击 change system locale选择</code></pre><h2 id="2-Cmd"><a href="#2-Cmd" class="headerlink" title="2. Cmd"></a>2. Cmd</h2><pre class=" language-shell"><code class="language-shell">where cmd #类似Linux中where 命令find /r 目录名 %变量名 in (匹配模式1,匹配模式2) do 命令for /r 目录名 %i in (匹配模式1,匹配模式2) do @echo %ifor /r TestDir %i in (*) do @echo %i  #将TestDir目录及所有子目录中所有的文件列举出来for /r TestDir %i in (*.txt) do @echo %i  #在TestDir目录所有子目录中找出所有的txt文件for /r TestDir %i in (.txt,.jpg) do @echo %i #找出所有的txt及jpg文件for /r TestDir %i in (test) do @echo %i  #找出所有文件名中包含test的文件Tree   #罗列文件目录</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OperationSystem </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typoro Command</title>
      <link href="/2020/04/26/ruan-jian-gong-ju/hexotypora/typoro-command/"/>
      <url>/2020/04/26/ruan-jian-gong-ju/hexotypora/typoro-command/</url>
      
        <content type="html"><![CDATA[<blockquote><p>​      Typora 是一个 Markdown 文本编辑器，它支持且仅支持 Markdown 语法的文本编辑。在 <a href="https://typora.io/" target="_blank" rel="noopener">Typora 官网</a> 上他们将 Typora 描述为 「A truly <strong>minimal</strong> markdown editor. 」</p></blockquote><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h2><pre class=" language-shell"><code class="language-shell">#1 安装依赖包 sudo apt-get install libapt-pkg-dev  #2 安装、更新 sudo apt-get install apt-transport-httpssudo apt-get update#3 安装Typora源wget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -sudo add-apt-repository ‘deb https://typora.io/linux ./‘sudo apt-get update#4 安装typora sudo apt-get install typora#首行缩进&emsp;&emsp;春天来了，又到了万物复苏的季节。#任务列表- [ ] 一次性水杯- [x] 西瓜#各种表情链接： https://www.webfx.com/tools/emoji-cheat-sheet/</code></pre><h2 id="2-图片排版"><a href="#2-图片排版" class="headerlink" title="2. 图片排版"></a>2. 图片排版</h2><p><strong>方法一：嵌入HTML代码</strong><br>使用img标签</p><pre class=" language-html"><code class="language-html">&lt;img src="./xxx.png" width = "300" height = "200" alt="图片名称" align=center /><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">'</span> <span class="token punctuation">'</span></span><span class="token style-attr language-css"><span class="token attr-name"> <span class="token attr-name">style</span></span><span class="token punctuation">='</span><span class="token attr-value"><span class="token property">float</span><span class="token punctuation">:</span>right<span class="token punctuation">;</span> <span class="token property">width</span><span class="token punctuation">:</span><span class="token number">300</span>px<span class="token punctuation">;</span><span class="token property">height</span><span class="token punctuation">:</span><span class="token number">100</span> px</span><span class="token punctuation">'</span></span><span class="token punctuation">/></span></span>#或者<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">align</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>center<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>图片地址<span class="token punctuation">"</span></span> <span class="token attr-name">height</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>300px<span class="token punctuation">"</span></span> <span class="token attr-name">alt</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>图片说明<span class="token punctuation">"</span></span> <span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>div</span><span class="token punctuation">></span></span></code></pre><p><strong>方法二：预定义类</strong></p><pre class=" language-html"><code class="language-html">#居中对齐，img间不要换行，否则识别不了<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>center</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>half<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>图片链接<span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>图片链接<span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>图片链接<span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>center</span><span class="token punctuation">></span></span>#左对齐并排<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>figure</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>third<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span><span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span><span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>img</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span><span class="token punctuation">"</span></span> <span class="token attr-name">width</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>200<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>figure</span><span class="token punctuation">></span></span></code></pre><h2 id="3-数学公式"><a href="#3-数学公式" class="headerlink" title="3. 数学公式"></a>3. 数学公式</h2><p><strong>开启行内公式</strong>：文件→偏好设置→Markdown，勾选内联公式，重启typora    </p><p><strong>分数，平方</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\frac{7x+5}{1+y^2}$，$1/2$</td><td align="left">\frac{7x+5}{1+y^2} ,    1/2</td></tr></tbody></table><p><strong>下标</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$z=z_l$ , $z=z^1$</td><td align="left">下标： z=z_l,  上标 z=z^1</td></tr></tbody></table><p><strong>省略号</strong></p><table><thead><tr><th align="left">省略号</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">⋯</td><td align="left">\cdots</td></tr></tbody></table><p><strong>开根号</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\sqrt{2};\sqrt[n]{3}$</td><td align="left">\sqrt{2};\sqrt[n]{3}</td></tr></tbody></table><p><strong>花括号</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$c(u)=\begin{cases} \sqrt\frac{1}{N}，u=0\ \sqrt\frac{2}{N}， u\neq0\end{cases}$</td><td align="left">c(u)=\begin{cases} \sqrt\frac{1}{N}，u=0\ \sqrt\frac{2}{N}， u\neq0\end{cases}     ,花括号</td></tr><tr><td align="left">$a \quad b$</td><td align="left">a \quad b  ,空格</td></tr></tbody></table><p><strong>矢量</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\vec{a} \cdot \vec{b}=0$</td><td align="left">\vec{a} \cdot \vec{b}=0</td></tr></tbody></table><p><strong>积分</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\int ^2_3 x^2 {\rm d}x$</td><td align="left">\int ^2_3 x^2 {\rm d}x</td></tr></tbody></table><p><strong>极限</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\lim_{n\rightarrow+\infty} n$</td><td align="left">\lim_{n\rightarrow+\infty} n</td></tr></tbody></table><p><strong>累加</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\sum \frac{1}{i^2}$</td><td align="left">\sum \frac{1}{i^2}</td></tr></tbody></table><p><strong>累乘</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\prod \frac{1}{i^2}$</td><td align="left">\prod \frac{1}{i^2}</td></tr></tbody></table><p><strong>希腊字母</strong></p><table><thead><tr><th align="left">大写</th><th align="left">markdown</th><th align="left">小写</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">A</td><td align="left">A</td><td align="left">α</td><td align="left">\alpha</td></tr><tr><td align="left">B</td><td align="left">B</td><td align="left">β</td><td align="left">\beta</td></tr><tr><td align="left">Γ</td><td align="left">\Gamma</td><td align="left">γ</td><td align="left">\gamma</td></tr><tr><td align="left">Δ</td><td align="left">\Delta</td><td align="left">δ</td><td align="left">\delta</td></tr><tr><td align="left">E</td><td align="left">E</td><td align="left">ϵ</td><td align="left">\epsilon</td></tr><tr><td align="left"></td><td align="left"></td><td align="left">ε</td><td align="left">\varepsilon</td></tr><tr><td align="left">Z</td><td align="left">Z</td><td align="left">ζ</td><td align="left">\zeta</td></tr><tr><td align="left">H</td><td align="left">H</td><td align="left">η</td><td align="left">\eta</td></tr><tr><td align="left">Θ</td><td align="left">\Theta</td><td align="left">θ</td><td align="left">\theta</td></tr><tr><td align="left">I</td><td align="left">I</td><td align="left">ι</td><td align="left">\iota</td></tr><tr><td align="left">K</td><td align="left">K</td><td align="left">κ</td><td align="left">\kappa</td></tr><tr><td align="left">Λ</td><td align="left">\Lambda</td><td align="left">λ</td><td align="left">\lambda</td></tr><tr><td align="left">M</td><td align="left">M</td><td align="left">μ</td><td align="left">\mu</td></tr><tr><td align="left">N</td><td align="left">N</td><td align="left">ν</td><td align="left">\nu</td></tr><tr><td align="left">Ξ</td><td align="left">\Xi</td><td align="left">ξ</td><td align="left">\xi</td></tr><tr><td align="left">O</td><td align="left">O</td><td align="left">ο</td><td align="left">\omicron</td></tr><tr><td align="left">Π</td><td align="left">\Pi</td><td align="left">π</td><td align="left">\pi</td></tr><tr><td align="left">P</td><td align="left">P</td><td align="left">ρ</td><td align="left">\rho</td></tr><tr><td align="left">Σ</td><td align="left">\Sigma</td><td align="left">σ</td><td align="left">\sigma</td></tr></tbody></table><table><thead><tr><th align="left">大写</th><th align="left">markdown</th><th align="left">小写</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">T</td><td align="left">T</td><td align="left">τ</td><td align="left">\tau</td></tr><tr><td align="left">Υ</td><td align="left">\Upsilon</td><td align="left">υ</td><td align="left">\upsilon</td></tr><tr><td align="left">Φ</td><td align="left">\Phi</td><td align="left">ϕ</td><td align="left">\phi</td></tr><tr><td align="left"></td><td align="left"></td><td align="left">φ</td><td align="left">\varphi</td></tr><tr><td align="left">X</td><td align="left">X</td><td align="left">χ</td><td align="left">\chi</td></tr><tr><td align="left">Ψ</td><td align="left">\Psi</td><td align="left">ψ</td><td align="left">\psi</td></tr><tr><td align="left">Ω</td><td align="left">\Omega</td><td align="left">ω</td><td align="left">\omega</td></tr></tbody></table><p><strong>三角函数</strong></p><table><thead><tr><th align="left">三角函数</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">sin</td><td align="left">\sin</td></tr></tbody></table><p><strong>对数函数</strong></p><table><thead><tr><th align="left">算式</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">ln15</td><td align="left">\ln15</td></tr><tr><td align="left">log210</td><td align="left">\log_2 10</td></tr><tr><td align="left">lg7</td><td align="left">\lg7</td></tr></tbody></table><p><strong>关系运算符</strong></p><table><thead><tr><th align="left">运算符</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">±</td><td align="left">\pm</td></tr><tr><td align="left">×</td><td align="left">\times</td></tr><tr><td align="left">÷</td><td align="left">\div</td></tr><tr><td align="left">∑</td><td align="left">\sum</td></tr><tr><td align="left">∏</td><td align="left">\prod</td></tr><tr><td align="left">≠</td><td align="left">\neq</td></tr><tr><td align="left">≤</td><td align="left">\leq</td></tr><tr><td align="left">≥</td><td align="left">\geq</td></tr></tbody></table><p><strong>其它特殊字符</strong></p><table><thead><tr><th align="left">符号</th><th align="left">markdown</th></tr></thead><tbody><tr><td align="left">$\forall$</td><td align="left">\forall</td></tr><tr><td align="left">$\infty$</td><td align="left">\infty</td></tr><tr><td align="left">$\emptyset$</td><td align="left">\emptyset</td></tr><tr><td align="left">$\exists$</td><td align="left">\exists</td></tr><tr><td align="left">$\nabla$</td><td align="left">\nabla</td></tr><tr><td align="left">$\bot$</td><td align="left">\bot</td></tr><tr><td align="left">$\angle$</td><td align="left">\angle</td></tr><tr><td align="left">$\because$</td><td align="left">\because</td></tr><tr><td align="left">$\therefore$</td><td align="left">\therefore</td></tr></tbody></table><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Typora </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo Blog Introduce</title>
      <link href="/2020/04/26/ruan-jian-gong-ju/hexotypora/hexo-blog-introduce/"/>
      <url>/2020/04/26/ruan-jian-gong-ju/hexotypora/hexo-blog-introduce/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is my very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a>.</p></blockquote><h2 id="Hexo-Introduce"><a href="#Hexo-Introduce" class="headerlink" title="Hexo Introduce"></a>Hexo Introduce</h2><blockquote><ul><li>Hexo is a fast, simple and powerful blog framework. You write posts in <a href="http://daringfireball.net/projects/markdown/" target="_blank" rel="noopener">Markdown</a> (or other markup languages) and Hexo generates static files with a beautiful theme in seconds.</li><li>Hexo+github+gitee blog deployment <a href="https://yafine66.gitee.io/posts/4ab2.html#toc-heading-60" target="_blank" rel="noopener">tutorial</a><ul><li>download Git&amp;&amp;Node.js</li><li>Github Register &amp;&amp; GithubPage Create</li><li>Configure Git user&amp;&amp;mail</li><li>Install Theme &amp;&amp; Config</li><li>Config Some Plugins</li></ul></li><li>Good Github Page Recommand:<ul><li><a href="https://mazhuang.org/" target="_blank" rel="noopener">https://mazhuang.org/</a></li><li><a href="http://www.liberxue.com/" target="_blank" rel="noopener">http://www.liberxue.com/</a></li><li><a href="https://rickfang666.github.io/about/" target="_blank" rel="noopener">https://rickfang666.github.io/about/</a></li><li><a href="https://ahrilove.top/" target="_blank" rel="noopener">https://ahrilove.top/</a></li></ul></li></ul></blockquote><h2 id="Hexo-Command"><a href="#Hexo-Command" class="headerlink" title="Hexo Command"></a>Hexo Command</h2><pre class=" language-bash"><code class="language-bash">$ <span class="token function">npm</span> <span class="token function">install</span> hexo -g <span class="token comment" spellcheck="true">#安装  </span>$ <span class="token function">npm</span> update hexo -g <span class="token comment" spellcheck="true">#升级  </span>$ hexo init <span class="token comment" spellcheck="true">#初始化</span>$ hexo new page <span class="token string">"categories"</span>  <span class="token comment" spellcheck="true">#新建页面</span><span class="token comment" spellcheck="true"># 简写</span>$ hexo n <span class="token string">"我的博客"</span> <span class="token operator">==</span> hexo new <span class="token string">"我的博客"</span> <span class="token comment" spellcheck="true">#新建文章</span>$ hexo p <span class="token operator">==</span> hexo publish$ hexo g <span class="token operator">==</span> hexo generate<span class="token comment" spellcheck="true">#生成</span>$ hexo s <span class="token operator">==</span> hexo server <span class="token comment" spellcheck="true">#启动服务预览  对跟配置文件修改需要重启</span>$ hexo d <span class="token operator">==</span> hexo deploy<span class="token comment" spellcheck="true">#部署</span><span class="token comment" spellcheck="true"># 服务器</span>$ hexo server <span class="token comment" spellcheck="true">#Hexo 会监视文件变动并自动更新，您无须重启服务器。</span>$ hexo server -s <span class="token comment" spellcheck="true">#静态模式</span>$ hexo server -p 5000 <span class="token comment" spellcheck="true">#更改端口</span>$ hexo server -i 192.168.1.1 <span class="token comment" spellcheck="true">#自定义 IP</span>$ hexo clean <span class="token comment" spellcheck="true">#清除缓存db.json 网页正常情况下可以忽略此条命令</span><span class="token comment" spellcheck="true">#需要删掉用命令新建的文章或页面时，只需要进入 Hexo 根目录下的 source 文件夹，删除对应文件或文件夹即可</span>$ hexo g <span class="token comment" spellcheck="true">#生成静态页面至public目录</span>$ hexo s <span class="token comment" spellcheck="true">#开启预览访问端口（默认端口4000，'ctrl + c'关闭server）</span>$ hexo d <span class="token comment" spellcheck="true">#将.deploy目录部署到GitHub</span><span class="token comment" spellcheck="true">#监视文件变动</span>hexo generate --watch <span class="token comment" spellcheck="true">#监视文件变动</span></code></pre><blockquote><table><thead><tr><th align="left">配置选项</th><th align="left">默认值</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">title</td><td align="left"><code>Markdown</code> 的文件标题</td><td align="left">文章标题，强烈建议填写此选项</td></tr><tr><td align="left">date</td><td align="left">文件创建时的日期时间</td><td align="left">发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td align="left">author</td><td align="left">根 <code>_config.yml</code> 中的 <code>author</code></td><td align="left">文章作者</td></tr><tr><td align="left">img</td><td align="left"><code>featureImages</code> 中的某个值</td><td align="left">文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径。如: <a href="https://yafine66.gitee.io/go.html?url=aHR0cDovL3h4eC5jb20veHh4LmpwZw==" target="_blank" rel="noopener">http://xxx.com/xxx.jpg</a></td></tr><tr><td align="left">top</td><td align="left"><code>true</code></td><td align="left">推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td align="left">cover</td><td align="left"><code>false</code></td><td align="left"><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td align="left">coverImg</td><td align="left">无</td><td align="left"><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td align="left">password</td><td align="left">无</td><td align="left">文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 verifyPassword选项</td></tr><tr><td align="left">toc</td><td align="left"><code>true</code></td><td align="left">是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td align="left">mathjax</td><td align="left"><code>false</code></td><td align="left">是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td align="left">summary</td><td align="left">无</td><td align="left">文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td align="left">categories</td><td align="left">无</td><td align="left">文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td align="left">tags</td><td align="left">无</td><td align="left">文章标签，一篇文章可以多个标签</td></tr><tr><td align="left">reprintPolicy</td><td align="left">cc_by</td><td align="left">文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Operation</title>
      <link href="/2020/03/16/ruan-jian-gong-ju/linux/linux-operation/"/>
      <url>/2020/03/16/ruan-jian-gong-ju/linux/linux-operation/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux-命令"><a href="#Linux-命令" class="headerlink" title="Linux 命令"></a>Linux 命令</h2><h3 id="链接-ln"><a href="#链接-ln" class="headerlink" title="链接  ln"></a>链接  ln</h3><pre class=" language-shell"><code class="language-shell">sudo ln -sf /usr/bin/g++-8 /usr/bin/g++ln - make links between filesSYNOPSIS       ln [OPTION]... [-T] TARGET LINK_NAME   (1st form)       ln [OPTION]... TARGET                  (2nd form)       ln [OPTION]... TARGET... DIRECTORY     (3rd form)       ln [OPTION]... -t DIRECTORY TARGET...  (4th form)</code></pre><h3 id="man-命令"><a href="#man-命令" class="headerlink" title="man 命令"></a>man 命令</h3><pre><code>man -b (向前翻一屏)  space (向后翻一屏)  /keyword 查找  n: 下一个whatis command # 查询命令执行什么功能</code></pre><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><pre class=" language-bash"><code class="language-bash">Ctrl+c <span class="token comment" spellcheck="true">#在命令行下起着终止当前执行程序的作用，</span>Ctrl+d  <span class="token comment" spellcheck="true">#相当于exit命令，退出当前shell</span>win    <span class="token comment" spellcheck="true">#搜索浏览程序文件音乐文件</span>ctrl+L <span class="token comment" spellcheck="true">#清除屏幕</span>ctrl+A  <span class="token comment" spellcheck="true">#光标移到行首</span>super+R <span class="token comment" spellcheck="true"># terminal</span>ctrl+shift+prtsc  <span class="token comment" spellcheck="true">#截屏到剪切板</span>super+h <span class="token comment" spellcheck="true">#隐藏窗口</span>super+up <span class="token comment" spellcheck="true">#窗口最大化</span>super+down <span class="token comment" spellcheck="true">#窗口最小话</span></code></pre><h3 id="压缩包操作"><a href="#压缩包操作" class="headerlink" title="压缩包操作"></a>压缩包操作</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">tar</span> -zxvf 4.1.2.tar.gzunzip -d /temp test.zip  <span class="token comment" spellcheck="true">#解压到指定的目录下，需要用到-d参数</span></code></pre><h3 id="文件下载"><a href="#文件下载" class="headerlink" title="文件下载"></a>文件下载</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">wget</span> -O  <span class="token comment" spellcheck="true">#下载并以不同的文件名保存</span><span class="token function">wget</span> -b <span class="token comment" spellcheck="true">#后台下载   tail -f wget-log  查看下载速度</span><span class="token function">wget</span> –spider url <span class="token comment" spellcheck="true">#测试下载链接是否可用等等</span></code></pre><h3 id="软件安装命令-dpkg-apt-snap-ppa-使用"><a href="#软件安装命令-dpkg-apt-snap-ppa-使用" class="headerlink" title="软件安装命令 dpkg | apt | snap |ppa 使用:"></a>软件安装命令 dpkg | apt | snap |<strong>ppa 使用</strong>:</h3><pre class=" language-bash"><code class="language-bash">dpkg -p package-name  <span class="token comment" spellcheck="true">#显示包的具体信息</span>dpkg -s package-name  <span class="token comment" spellcheck="true">#报告指定包的状态信息    </span>dpkg -l                <span class="token comment" spellcheck="true">#显示所有已经安装的Deb包，同时显示版本号以及简短说明</span>dpkg -P            <span class="token comment" spellcheck="true">#删除一个包（包括配置信息）    </span>dpkg -A package_file  <span class="token comment" spellcheck="true">#从软件包里面读取软件的信息    </span>dpkg -i <span class="token operator">&lt;</span>.deb <span class="token function">file</span> name<span class="token operator">></span>  <span class="token comment" spellcheck="true">#安装软件    </span>apt update<span class="token operator">|</span><span class="token function">install</span><span class="token operator">|</span>upgradable<span class="token operator">|</span>remove<span class="token operator">|</span>purge<span class="token operator">|</span>search<span class="token comment" spellcheck="true"># tab键自动补全,apt下载时有锁</span><span class="token comment" spellcheck="true">#snap是一种全新的软件包管理方式，它类似一个容器拥有一个应用程序所有的文件和库，各个应用程序之间完全独立。所以使用snap包的好处就是它解决了应用程序之间的依赖问题，使应用程序之间更容易管理。但是由此带来的问题就是它占用更多的磁盘空间.snap软件包一般安装在/snap目录下</span>snap list <span class="token comment" spellcheck="true">#罗列</span>snap <span class="token function">find</span> <span class="token operator">|</span> <span class="token function">install</span> <span class="token operator">|</span> refresh <span class="token operator">|</span> remove packagesnap changes <span class="token comment" spellcheck="true"># 查看正在进行的下载</span>snap abort <span class="token function">id</span> <span class="token comment" spellcheck="true"># 停止下载</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> ppa-purgeTo purge a PPA, you must use the following command:<span class="token function">sudo</span> ppa-purge ppa:someppa/ppa     删除ppa 及对应软件<span class="token function">sudo</span> add-apt-repository ppa:someppa/ppa<span class="token function">sudo</span> apt update<span class="token function">sudo</span> add-apt-repository --remove ppa:someppa/ppa</code></pre><h3 id="网络命令-netstat-top"><a href="#网络命令-netstat-top" class="headerlink" title="网络命令 netstat ,top"></a>网络命令 netstat ,top</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># net-tools   包括ifconfig,netstat 等网络工具</span>top: <span class="token comment" spellcheck="true">#查看电脑个进程占用资源情况  b 高亮显示当前进程.</span><span class="token function">netstat</span> -a :Listing all ports <span class="token punctuation">(</span>both TCP and UDP<span class="token punctuation">)</span> using option.<span class="token function">netstat</span> -l <span class="token keyword">:</span> active listening ports connections<span class="token function">netstat</span> -s <span class="token keyword">:</span> displays statistics by protocol<span class="token function">netstat</span> -i <span class="token keyword">:</span> show the network interface<span class="token function">netstat</span> -r <span class="token keyword">:</span> show the routing<span class="token function">netstat</span> -ie <span class="token keyword">:</span> like <span class="token function">ifconfig</span><span class="token function">netstat</span> -ap <span class="token operator">|</span> <span class="token function">grep</span> http <span class="token keyword">:</span> <span class="token function">find</span> the listening program<span class="token comment" spellcheck="true">#查找程序是否运行</span><span class="token comment" spellcheck="true">#pgrep command – Looks through the currently running bash processes on Linux and lists the process IDs (PID) on screen.</span>pgrep nginx<span class="token comment" spellcheck="true">#pidof command – Find the process ID of a running program on Linux or Unix-like system</span>pidof nginx<span class="token comment" spellcheck="true">#ps command – Get information about the currently running Linux or Unix processes, including their process identification numbers (PIDs).</span><span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> nginx</code></pre><h3 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h3><pre class=" language-shell"><code class="language-shell">set | grep -i all_proxy# Unset socks proxyunset all_proxy     #根据上个命令输出决定是否用大写还是小写unset ALL_PROXY      #系统中的设置还在# Install missing dependencies:pip install pysocks# Reset proxysource ~/.bashrc</code></pre><h3 id="evince-pdf-文件查看"><a href="#evince-pdf-文件查看" class="headerlink" title="evince  pdf 文件查看"></a>evince  pdf 文件查看</h3><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><h3 id="CPU-温度"><a href="#CPU-温度" class="headerlink" title="CPU 温度"></a>CPU 温度</h3><pre class=" language-shell"><code class="language-shell">sudo apt install lm-sensors hddtempsudo sensors-detectsensors#如果有虚拟温度显示sudo apt install psensor  #设置开机自启,监控温度</code></pre><h3 id="VimOp"><a href="#VimOp" class="headerlink" title="VimOp"></a>VimOp</h3><table><thead><tr><th align="center">操作符</th><th align="right">作用</th></tr></thead><tbody><tr><td align="center"><code>control</code>+<code>A</code></td><td align="right">移动光标至行首</td></tr><tr><td align="center"><code>control</code>+<code>E</code></td><td align="right">移动光标至行尾</td></tr><tr><td align="center"><code>control</code>+<code>U</code></td><td align="right">删除整行命令</td></tr><tr><td align="center"><code>control</code>+<code>K</code></td><td align="right">删除光标后面的内容</td></tr><tr><td align="center"><code>option</code>+<code>←</code>、<code>→</code></td><td align="right">按词组移动光标</td></tr><tr><td align="center">!!</td><td align="right">执行上一条命令</td></tr><tr><td align="center">！</td><td align="right">重复命令，例如$ ! -3 执行前面三条命令; $ ! pod 重复最近一次pod命令</td></tr><tr><td align="center">|</td><td align="right">将左侧的命令结果人给右侧命令</td></tr><tr><td align="center">&gt;</td><td align="right">等待前一天命令结束</td></tr><tr><td align="center">&amp;&amp;</td><td align="right">多条命令同时执行</td></tr><tr><td align="center">&amp;</td><td align="right">不管前面执行是否成功都执行后面的命令</td></tr></tbody></table><h3 id="Cmake"><a href="#Cmake" class="headerlink" title="Cmake"></a>Cmake</h3><ul><li>中find_package() 工作原理：<a href="https://www.jianshu.com/p/46e9b8a6cb6a" target="_blank" rel="noopener">https://www.jianshu.com/p/46e9b8a6cb6a</a></li></ul><pre class=" language-shell"><code class="language-shell">cmake-gui #图像化cmakecmake --versionapt-get remove cmakecd /usr/local/srcwget https://github.com/Kitware/CMake/releases/download/v3.15.3/cmake-3.15.3.tar.gztar -xvzf cmake-3.15.3.tar.gzcd cmake-3.15.3./bootstrapmake -j4make install##python 使用C++11 框架 pylind11</code></pre><h3 id="gcc-cpp-g-区别"><a href="#gcc-cpp-g-区别" class="headerlink" title="gcc cpp g++ 区别"></a>gcc cpp g++ 区别</h3><pre class=" language-shell"><code class="language-shell">gcc和g++的主要区别# 1. 对于 *.c和*.cpp文件，gcc分别当做c和cpp文件编译（c和cpp的语法强度是不一样的）# 2. 对于 *.c和*.cpp文件，g++则统一当做cpp文件编译# 3. 使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接STL# 4. gcc在编译C文件时，可使用的预定义宏是比较少的# 5. gcc在编译cpp文件时/g++在编译c文件和cpp文件时（这时候gcc和g++调用的都是cpp文件的编译器），会加入一些额外的宏，这些宏如下：# 6. 在用gcc编译c++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价，它们的区别不仅仅是这个#gcc 版本gcc -versionsudo apt-get install gcc-5 g++-5sudo update-alternatives --install /usr/bin/gcc gcc/usr/bin/gcc-5 50  #change privilege</code></pre><h3 id="SCP文件互传"><a href="#SCP文件互传" class="headerlink" title="SCP文件互传"></a>SCP文件互传</h3><pre class=" language-shell"><code class="language-shell">scp ubuntu@140.143.210.30:/usr/local/apache-tomcat-9.0.22/webapps/temp.zip ~#scp 命令将服务器上文件拷贝至本地</code></pre><h3 id="ubuntu-VMWare-worstation-pro-15"><a href="#ubuntu-VMWare-worstation-pro-15" class="headerlink" title="ubuntu VMWare worstation pro 15"></a>ubuntu VMWare worstation pro 15</h3><pre class=" language-shell"><code class="language-shell">#下载地址 https://www.vmware.com/products/workstation-pro/workstation-pro-evaluation.html#VMware Workstation All Key：https://www.cnblogs.com/dunitian/p/8414055.htmlsudo ./VMWare-*sudo vmware-installer -u vmware-workstation  #卸载  </code></pre><h3 id="网速测量speedtest"><a href="#网速测量speedtest" class="headerlink" title="网速测量speedtest"></a>网速测量speedtest</h3><pre class=" language-shell"><code class="language-shell">git clone https://github.com/sivel/speedtest-cli.gitcd speedtest-clipython speedtest.py#具体可以看下readme操作，可以通过pip 方式安装</code></pre><h3 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h3><pre class=" language-shell"><code class="language-shell">#方式一：  #      通过官方网站（https://pytorch.org/）给的方法进行安装，根据自己的系统环境及相应python，CUDA版本运行相应的命令进行安装。如果电脑中只有python3，这里的pip3可以直接就用pip代替。conda install pytorch torchvision cudatoolkit=10.1 -c pytorch#遇问题 有关proxy#解决方案: 在 .bashrc 中添加: export all_proxy="socks5://127.0.0.1:1080"#cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.1.243-h6bb024c_0#  ninja              pkgs/main/linux-64::ninja-1.9.0-py37hfd86e86_0 # pytorch            pytorch/linux-64::pytorch-1.3.1-py3.7_cuda10.1.243_cudnn7.6.3_0 # torchvision        pytorch/linux-64::torchvision-0.4.2-py37_cu101#方式二：   https://download.pytorch.org/whl/torch_stable.html#    直接下载torch的whl文件，通过pip install （路径+whl文件名）#    可以下载到本地 anaconda\install\Lib\site-packages路径下，或者在线下载安装</code></pre><h3 id="caffe-安装"><a href="#caffe-安装" class="headerlink" title="caffe 安装"></a>caffe 安装</h3><pre class=" language-shell"><code class="language-shell">sudo apt install caffe-cudasudo apt build-dep caffe-cuda       # dependencies for CUDA versionsudo vim /etc/apt/sources.list   #将deb-src 注释掉#遇到问题 dpkg-deb: error: paste subprocess was killed by signal (Broken pipe)#Errors were encountered while processing:# /var/cache/apt/archives/nvidia-cuda-dev_9.1.85-3ubuntu1_amd64.deb#sudo dpkg -i --force-overwrite /var/cache/apt/archives/nvidia-418_418.39-0ubuntu1_amd64.deb#sudo apt --fix-broken install</code></pre><h3 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start application.service   <span class="token comment" spellcheck="true">#同 systemctl start application  ,系统默认查找application.service    stop, restart,reload</span><span class="token function">sudo</span> systemctl enable/disable application.service   <span class="token comment" spellcheck="true">#start a service at boot create a symbolic link from the system’s copy of the service file (usually in /lib/systemd/system or /etc/systemd/system) into the location on disk where systemd looks for autostart files (usually /etc/systemd/system/some_target.target.wants</span>systemctl status application.service  <span class="token comment" spellcheck="true">#查看服务状态</span>systemctl list-units  <span class="token comment" spellcheck="true"># list all of the units that systemd currently has active </span>systemctl list-dependencies application.service  <span class="token comment" spellcheck="true">#查找关系依赖树</span></code></pre><h3 id="搜狗输入法"><a href="#搜狗输入法" class="headerlink" title="搜狗输入法"></a>搜狗输入法</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> remove ibus<span class="token function">sudo</span> <span class="token function">apt-get</span> purge ibus     <span class="token comment" spellcheck="true">#purge  </span><span class="token function">sudo</span>  <span class="token function">apt-get</span> remove indicator-keyboard<span class="token function">sudo</span> apt <span class="token function">install</span> fcitx-table-wbpy fcitx-config-gtkim-config -n fcitx选择系统设置语言 https://pinyin.sogou.com/linux/  <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -ffcitx-config-gtk3fcitx设置 <span class="token operator">>></span>附加组件<span class="token operator">>></span>勾选高级 <span class="token operator">>></span>取消经典界面Configure<span class="token operator">>></span>  Addon  <span class="token operator">>></span>Advanced<span class="token operator">>></span>Classic,sogouyun<span class="token comment" spellcheck="true">#重启 把sogoupinyin放在第二个</span><span class="token comment" spellcheck="true">#只用sogou 输入法一种就行了</span><span class="token comment" spellcheck="true">#搜狗云输入的锅，在fcitx配置里把搜狗云拼音这个选项去掉就可以很完美的解决这问题了  解决占cpu</span><span class="token comment" spellcheck="true">#中文输入时没有汉字提示时下载一个 皮肤 ,用搜狗软件打开就行可</span><span class="token comment" spellcheck="true">#https://pinyin.sogou.com/skins/detail/view/info/588600?rf=cate_31_sign&amp;tf=p</span></code></pre><h3 id="多线程下载软件源"><a href="#多线程下载软件源" class="headerlink" title="多线程下载软件源:"></a>多线程下载软件源:</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> add-apt-repository ppa:apt-fast/stable<span class="token function">sudo</span> <span class="token function">apt-get</span> update</code></pre><h3 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> apt <span class="token function">install</span> openjdk-11-jdk</code></pre><h3 id="VSCODE"><a href="#VSCODE" class="headerlink" title="VSCODE"></a>VSCODE</h3><ul><li><p>格式化代码</p><pre><code>vs code格式化代码的快捷键如下：（来源于这里）On Windows Shift + Alt + F.On Mac Shift + Option + F.On Ubuntu Ctrl + Shift + I.</code></pre></li><li><p>常用插件</p><ul><li>Beautify</li><li>TODO Highlight</li><li>Code Spell Checker</li><li>IntelliSense for CSS class names in HTML</li></ul></li><li><p>删除多余空行  全局替换  ^\s*(?=\r?$)\n     Alt+R 正则表达式</p></li></ul><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> ubuntu-make  <span class="token comment" spellcheck="true"># 像这种开发软件去官网下载安装包</span><span class="token comment" spellcheck="true">#查看版本</span>code --versioncode <span class="token comment" spellcheck="true">#运行vscode</span><span class="token comment" spellcheck="true">#Ctrl+Shift+P打开命令面板</span><span class="token comment" spellcheck="true">#c_cpp_properties.json  该文件用于指定一般的编译环境，包括头文件路径，编译器的路径等。通过 Ctrl + Shift + p 打开命令行，键入关键字 "C++"，在下拉菜单中选择 "C/C++ Edit configuration"，系统即自动在 .vscode 目录下创建 c_cpp_properties.json 文件，供用户进行编译方面的环境配置。</span><span class="token punctuation">{</span>    <span class="token string">"configurations"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span>            <span class="token string">"name"</span><span class="token keyword">:</span> <span class="token string">"Linux"</span>,            <span class="token string">"includePath"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>                <span class="token string">"<span class="token variable">${workspaceFolder}</span>/**"</span>            <span class="token punctuation">]</span>,            <span class="token string">"defines"</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>,            <span class="token string">"compilerPath"</span><span class="token keyword">:</span> <span class="token string">"/usr/bin/gcc"</span>,            <span class="token string">"cStandard"</span><span class="token keyword">:</span> <span class="token string">"c11"</span>,            <span class="token string">"cppStandard"</span><span class="token keyword">:</span> <span class="token string">"c++17"</span>,            <span class="token string">"intelliSenseMode"</span><span class="token keyword">:</span> <span class="token string">"clang-x64"</span>        <span class="token punctuation">}</span>    <span class="token punctuation">]</span>,    <span class="token string">"version"</span><span class="token keyword">:</span> 4<span class="token punctuation">}</span><span class="token comment" spellcheck="true">#build.json  该文件用于指定程序的编译规则，即如何将源文件编译为可执行程序。通过 Ctrl + Shift + p 打开命令行，键入关键字 "task"，并在下拉菜单中选择 Tasks: Configure Default Build Task -> Create tassk.json file from template -> Others ，系统即自动在 .vscode 目录下创建 build.json 文件，供用户设置具体的编译规则</span><span class="token punctuation">{</span>    // See https://go.microsoft.com/fwlink/?LinkId<span class="token operator">=</span>733558    // <span class="token keyword">for</span> the documentation about the tasks.json <span class="token function">format</span>    <span class="token string">"version"</span><span class="token keyword">:</span> <span class="token string">"2.0.0"</span>,    <span class="token string">"tasks"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span>            <span class="token string">"label"</span><span class="token keyword">:</span> <span class="token string">"echo"</span>,            <span class="token string">"type"</span><span class="token keyword">:</span> <span class="token string">"shell"</span>,            <span class="token string">"command"</span><span class="token keyword">:</span> <span class="token string">"g++"</span>,                   //编译时执行的程序            <span class="token string">"args"</span><span class="token keyword">:</span> <span class="token punctuation">[</span><span class="token string">"-g"</span>, <span class="token string">"-o"</span>, <span class="token string">"test"</span>, <span class="token string">"test1.c"</span><span class="token punctuation">]</span>,    //传递给 <span class="token function">command</span> 的参数            <span class="token string">"problemMatcher"</span><span class="token keyword">:</span> <span class="token punctuation">[</span>                <span class="token string">"<span class="token variable">$gcc</span>"</span>            <span class="token punctuation">]</span>        <span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true"># Ctrl+Shift+p 打开命令行，选择 Tasks:Run Build Task 运行上述编译过程</span><span class="token comment" spellcheck="true">#launch.json  该文件主要与程序的调试相关。用户可通过 Ctrl+Shift+p 打开命令行，键入关键字 "launch",选择 "Debug:Open launch.json" -> "C++(GDB/LLDB)"，即可打开调试的配置文件 launch.json。在 VSCode 中，用户按 F5 即可进入调试模式，上述 launch.json 文件即设置在调试时的基本内容和要求。</span></code></pre><h3 id="indicator-sysmonitor"><a href="#indicator-sysmonitor" class="headerlink" title="indicator-sysmonitor"></a>indicator-sysmonitor</h3><p>一款可以监视 CPU 占用率、 CPU 温度、内存占用率、网速等系统信息的小软件，在桌面最上方进行显示。Top 的图形化命令</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># sudo add-apt-repository ppa:fossfreedom/indicator-sysmonitor  </span><span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> indicator-sysmonitor</code></pre><h3 id="GDebi"><a href="#GDebi" class="headerlink" title="GDebi"></a>GDebi</h3><pre class=" language-shell"><code class="language-shell">#若用 Ubuntu 自带的软件中心安装 deb 格式的文件不仅经常会崩溃而且会遇到各种各样的依赖问题。通过deb文件安装软件优选sudo apt-get install gdebi</code></pre><h3 id="Marp"><a href="#Marp" class="headerlink" title="Marp"></a>Marp</h3><p>用 Markdown 语法来制作 PPT，高效快速简洁实用，尤其是支持 LaTeX 语法，非常方便编辑大量的数学公式，值得推荐，官网有 deb 文件，下载后直接安装即可。</p><h3 id="新立得软件管理"><a href="#新立得软件管理" class="headerlink" title="新立得软件管理"></a>新立得软件管理</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> synaptic  <span class="token comment" spellcheck="true">#  全面高效地管理各种软件和依赖。</span></code></pre><h3 id="Tim"><a href="#Tim" class="headerlink" title="Tim"></a>Tim</h3><blockquote><p>Tim 安装   去官网 下载linux QQ  但qq上没有我的设备<br><a href="https://im.qq.com/linuxqq/download.html" target="_blank" rel="noopener">https://im.qq.com/linuxqq/download.html</a><br><a href="https://github.com/wszqkzqk/deepin-wine-ubuntu/releases" target="_blank" rel="noopener">https://github.com/wszqkzqk/deepin-wine-ubuntu/releases</a>   #wine的一个版本<br><a href="https://www.lulinux.com/archives/1319" target="_blank" rel="noopener">https://www.lulinux.com/archives/1319</a>  #deepin-wine Tim安装教程<br><strong>Winehq</strong>:<a href="https://wiki.winehq.org/Ubuntu_zhcn" target="_blank" rel="noopener">https://wiki.winehq.org/Ubuntu_zhcn</a>   学习如何使用  回去学习下winehq使用教程<a href="https://wiki.winehq.org/Wine_User' target=" _blank"="" rel="noopener" s_guide"="">https://wiki.winehq.org/Wine_User%27s_Guide</a><br>Usage: wine PROGRAM [ARGUMENTS…]   Run the specified program<br>       wine –help                   Display this help and exit<br>       wine –version                Output version information and exit<br>运行方式1:cd ‘.wine/drive_c/Games/Tron’<br>         wine tron.exe<br>运行方式2:wine start ‘C:\Games\Tron\tron.exe’<br>        wine start “C:\Games\Tron\tron.exe”<br>        wine start /unix “$HOME/installers/TronSetup.exe”<br>        wine quake.exe -map e1m1   #带参数<br>        wine start whatever.msi<br>         wine control<br>         wine uninstaller</p></blockquote><h3 id="mega网盘安装"><a href="#mega网盘安装" class="headerlink" title="mega网盘安装"></a>mega网盘安装</h3><blockquote><p><a href="https://mega.nz/sync" target="_blank" rel="noopener">https://mega.nz/sync</a>   去官网安装 需要联网</p></blockquote><h3 id="V2Ray-安装"><a href="#V2Ray-安装" class="headerlink" title="V2Ray 安装"></a>V2Ray 安装</h3><pre class=" language-shell"><code class="language-shell">#然后编辑`/etc/v2ray/config.json`文件service v2ray stop service v2ray start service v2ray status#https://github.com/FelisCatus/SwitchyOmega/wiki/GFWList</code></pre><ul><li><h3 id="v2ray-go-sh脚本阅读记录"><a href="#v2ray-go-sh脚本阅读记录" class="headerlink" title="#v2ray/go.sh脚本阅读记录"></a>#v2ray/go.sh脚本阅读记录</h3></li></ul><pre class=" language-bash"><code class="language-bash">$<span class="token comment" spellcheck="true"># 表示执行脚本传入参数的个数</span><span class="token variable">$*</span>  表示执行脚本传入参数列表$$ 表示进程id<span class="token variable">$@</span>表示执行脚本传入所有参数<span class="token variable">$0</span> 表示执行脚本名称<span class="token variable">$1</span> 表示第一个参数<span class="token variable">$2</span> 表示第二个参数<span class="token variable">$?</span> 表示脚本执行状态0正常，其他表示有错误<span class="token comment" spellcheck="true">#提取文件到某个位置函数  </span><span class="token comment" spellcheck="true">#获取系统本版/检查版本更新   getVersion()/checkUpdate()</span><span class="token comment" spellcheck="true">#检查系统架构  SysArch()</span><span class="token comment" spellcheck="true">#获得系统 install update 指令   'command -v apt-get' 判断系统是否有apt-get 指令</span><span class="token comment" spellcheck="true">#prompt 颜色设置  colorEcho()</span><span class="token comment" spellcheck="true">#下载文件   downloadv2ray()</span><span class="token comment" spellcheck="true"># echo $VER | head -n 1 | cut -d " " -f2`  </span><span class="token comment" spellcheck="true">#关闭或启动软件  stopV2ray() startV2ray() 通过检查systemctl/service 命令</span><span class="token comment" spellcheck="true">#copy 文件  copyFile()</span><span class="token comment" spellcheck="true">#添加执行权限 makeExecutable()</span><span class="token comment" spellcheck="true"># help() 帮助提示框</span>installInitScript<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> -n <span class="token string">"<span class="token variable">${SYSTEMCTL_CMD}</span>"</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">then</span>        <span class="token keyword">if</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">!</span> -f <span class="token string">"/etc/systemd/system/v2ray.service"</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>            <span class="token keyword">if</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">!</span> -f <span class="token string">"/lib/systemd/system/v2ray.service"</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>                <span class="token function">cp</span> <span class="token string">"<span class="token variable">${VSRC_ROOT}</span>/systemd/v2ray.service"</span> <span class="token string">"/etc/systemd/system/"</span>                systemctl <span class="token function">enable</span> v2ray.service            <span class="token keyword">fi</span>        <span class="token keyword">fi</span>        <span class="token keyword">return</span>    <span class="token keyword">elif</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> -n <span class="token string">"<span class="token variable">${SERVICE_CMD}</span>"</span> <span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">!</span> -f <span class="token string">"/etc/init.d/v2ray"</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>        installSoftware <span class="token string">"daemon"</span> <span class="token operator">||</span> <span class="token keyword">return</span> <span class="token variable">$?</span>        <span class="token function">cp</span> <span class="token string">"<span class="token variable">${VSRC_ROOT}</span>/systemv/v2ray"</span> <span class="token string">"/etc/init.d/v2ray"</span>        <span class="token function">chmod</span> +x <span class="token string">"/etc/init.d/v2ray"</span>        update-rc.d v2ray defaults    <span class="token keyword">fi</span>    <span class="token keyword">return</span><span class="token punctuation">}</span><span class="token function">sed</span> -i <span class="token string">"s/10086/<span class="token variable">${PORT}</span>/g"</span> <span class="token string">"/etc/v2ray/config.json"</span>  <span class="token comment" spellcheck="true">#学习这个指令</span>downloadV2Ray <span class="token operator">||</span> <span class="token keyword">return</span> <span class="token variable">$?</span>installV2Ray<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#包括下载到那个目录,copy了那些文件,如何根据配置文件进行配置的</span>remove<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span># 卸载停止服务,把安转时写入的文件全部删除      /etc/systemd/system/v2ray.service       /usr/bin/v2ray    /lib/systemd/system/v2ray.service    /etc/init.d/v2ray<span class="token punctuation">}</span></code></pre><h3 id="修改github-DNS"><a href="#修改github-DNS" class="headerlink" title="修改github DNS"></a>修改github DNS</h3><pre class=" language-shell"><code class="language-shell">#https://www.linuxidc.com/Linux/2019-05/158461.htm#github219.76.4.4 github-cloud.s3.amazonaws.com192.30.253.112 github.com151.101.185.194 github.global.ssl.fastly.netldd@ldd:~/v2ray$ sudo vim /etc/hostsldd@ldd:~/v2ray$ sudo /etc/init.d/networking restart </code></pre><h3 id="WPS-去官网下载"><a href="#WPS-去官网下载" class="headerlink" title="WPS 去官网下载"></a>WPS 去官网下载</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#http://www.wps.cn/product/wpslinux  </span><span class="token function">sudo</span> dpkg -i wps-office_10.1.0.6757_amd64.deb</code></pre><h3 id="IDEA下载"><a href="#IDEA下载" class="headerlink" title="IDEA下载"></a><a href="https://www.jetbrains.com/idea/download/#section=linux" target="_blank" rel="noopener">IDEA下载</a></h3><h3 id="Teamview-deb-安装"><a href="#Teamview-deb-安装" class="headerlink" title="Teamview   deb 安装"></a>Teamview   deb 安装</h3><h3 id="proxyee-down命令行安装-百度云下载神器"><a href="#proxyee-down命令行安装-百度云下载神器" class="headerlink" title="proxyee-down命令行安装  百度云下载神器"></a>proxyee-down命令行安装  百度云下载神器</h3><h3 id="docky-桌面工具"><a href="#docky-桌面工具" class="headerlink" title="docky 桌面工具"></a>docky 桌面工具</h3><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span>  docky   <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> gnome-tweak-tool <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> gnome-shell-extensions <span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> gnome-shell-extension-dashtodock<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> gnome-shell-extension-autohidetopbar<span class="token comment" spellcheck="true">#也可以在Ubuntu软件中直接搜索hide top bar</span><span class="token function">sudo</span> <span class="token function">apt-get</span> remove gnome-shell-extension-autohidetopbar <span class="token comment" spellcheck="true">#卸载</span><span class="token comment" spellcheck="true">#快捷键设置</span>gnome-screenshot -ac  <span class="token comment" spellcheck="true"># 也具有qq截图到快捷键功能</span><span class="token comment" spellcheck="true">#在打开——系统设置——>键盘——快捷键——自定义快捷键，然后输入名字和上边工具的命令</span></code></pre><h3 id="Opencv"><a href="#Opencv" class="headerlink" title="Opencv"></a>Opencv</h3><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">#python 包</span>pip uninstall opencv-pythonpip <span class="token function">install</span> opencv-contrib-python <span class="token comment" spellcheck="true">#opencv4. 源码编译安装， 也可以直接编译Android 依赖库</span><span class="token comment" spellcheck="true">#https://www.pluvet.com/archives/223.html 安装教程</span><span class="token function">sudo</span> add-apt-repository “deb http://security.ubuntu.com/ubuntu xenial-security main”<span class="token function">sudo</span> apt update<span class="token function">sudo</span> apt <span class="token function">install</span> libjasper1 libjasper-dev  <span class="token function">sudo</span> apt-fast <span class="token function">install</span> build-essential cmake libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-devcmake <span class="token punctuation">..</span><span class="token function">make</span> -j4<span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span></code></pre><h3 id="Python-命令转换"><a href="#Python-命令转换" class="headerlink" title="Python 命令转换"></a>Python 命令转换</h3><p>pip 切换镜像  最终写入文件 /home/ldd/.config/pip/pip.conf</p><pre class=" language-shell"><code class="language-shell">pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code></pre><p>方式一：系统默认一个版本，在另装一个版本，通过软连接</p><pre class=" language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 以后使用anaconda</span><span class="token comment" spellcheck="true">#查看当前默认Python版本</span>python --version <span class="token comment" spellcheck="true">#查看Python所在</span><span class="token function">which</span> is python<span class="token function">which</span> is python3<span class="token comment" spellcheck="true">#Python下载的库可以查看这里。/usr/local/lib/</span><span class="token comment" spellcheck="true">#显示Python代替版本信息</span>update-alternatives --list python<span class="token comment" spellcheck="true">#设置 /usr/bin/python3.5 设置的优先级为2 优先级越高越大</span>update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2<span class="token comment" spellcheck="true">#再次显示Python代替版本信息</span>update-alternatives --remove python /usr/bin/python2.7<span class="token comment" spellcheck="true">#切换版本</span><span class="token function">sudo</span> update-alternatives --config python<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3-pip <span class="token comment" spellcheck="true"># #安装Python3对应的pip3</span><span class="token function">sudo</span> pip3 <span class="token function">install</span> --upgrade pip   <span class="token comment" spellcheck="true">#推荐在管理员模式下更新</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python-pip  <span class="token comment" spellcheck="true">#安装Python2对应的pip</span><span class="token comment" spellcheck="true">#Pip  安装的库会放在这个目录下面：python2.7/site-packages；</span><span class="token comment" spellcheck="true">#pip3 新安装的库会放在这个目录下面：python3.6/site-packages；</span><span class="token comment" spellcheck="true">#参考https://www.cnblogs.com/carle-09/p/9907274.html</span><span class="token comment" spellcheck="true">#errorPermission denied: '/usr/local/lib/python3.6/dist-packages/cycler.py' Consider using the `--user` option or check the permissions.</span>pip3 <span class="token function">install</span> --user matplotlib  <span class="token comment" spellcheck="true">#The 'pip==9.0.3' distribution was not found and is required by the application</span><span class="token function">sudo</span> easy_install pip<span class="token operator">==</span>9.0.3  <span class="token comment" spellcheck="true">#解决</span></code></pre><p>方式二：安装anaconda，然后建立基于不同python版本的conda环境</p><p>方式三：建立虚拟机virtualenv，然后建立基于不同python版本的虚拟环境</p><h3 id="MySQL-安装"><a href="#MySQL-安装" class="headerlink" title="MySQL 安装"></a>MySQL 安装</h3><pre class=" language-shell"><code class="language-shell">sudo apt-get install mysql-serversudo mysql_secure_installation  #设置密码 liudongdongsudo mysql   #可以直接登录sudo systemctl start mysql</code></pre><h3 id="Net-core-安装"><a href="#Net-core-安装" class="headerlink" title=".Net core 安装"></a>.<a href="https://dotnet.microsoft.com/download/linux-package-manager/ubuntu18-04/sdk-current" target="_blank" rel="noopener">Net core 安装</a></h3><h3 id="mssql-server安装"><a href="#mssql-server安装" class="headerlink" title="mssql-server安装"></a><a href="https://docs.microsoft.com/zh-cn/sql/linux/quickstart-install-connect-ubuntu?view=sql-server-ver15#connect-locally" target="_blank" rel="noopener">mssql-server安装</a></h3><pre class=" language-shell"><code class="language-shell">sudo apt-fast install libodbc1 unixodbc msodbcsql mssql-tools unixodbc-dev</code></pre><h3 id="NVIDIA显卡驱动-cuda"><a href="#NVIDIA显卡驱动-cuda" class="headerlink" title="NVIDIA显卡驱动 cuda"></a>NVIDIA显卡驱动 cuda</h3><pre class=" language-bash"><code class="language-bash"> <span class="token comment" spellcheck="true">#驱动安装</span> <span class="token function">sudo</span> ubuntu-drivers devices  查看系统支持的显卡设备并下载<span class="token comment" spellcheck="true">#**系统设置** > **细节**窗口，你会发现Ubuntu正在使用Nvidia显卡。</span>lspci -k <span class="token operator">|</span> <span class="token function">grep</span> -A 2 -i <span class="token string">"VGA"</span>software-properties-gtknvidia-settings       <span class="token comment" spellcheck="true">#打开nvidia 设置软件页面</span>ubuntu-drivers devices    <span class="token comment" spellcheck="true">#推荐显卡和驱动</span><span class="token function">sudo</span> ubuntu-drivers autoinstall  <span class="token comment" spellcheck="true">#显示推荐的驱动</span><span class="token function">sudo</span> <span class="token function">apt-get</span> updateapt search nvidia-driver-418lshw -C video   <span class="token comment" spellcheck="true">#查看设备       </span>lspci <span class="token operator">|</span> <span class="token function">grep</span> -i nvidia  <span class="token comment" spellcheck="true">#verify you have a cuda-Capble GPU</span><span class="token comment" spellcheck="true">#查看当前NVIDIA驱动版本</span><span class="token function">sudo</span> dpkg --list <span class="token operator">|</span> <span class="token function">grep</span> nvidia-*<span class="token comment" spellcheck="true">#查看本机GPU</span><span class="token function">uname</span> -r <span class="token comment" spellcheck="true">#current running kernel</span><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> linux-headers-<span class="token variable"><span class="token variable">$(</span><span class="token function">uname</span> -r<span class="token variable">)</span></span> <span class="token comment" spellcheck="true"># the kernel headers and development packages</span>gcc --version      <span class="token comment" spellcheck="true">#是否安装gcc</span><span class="token comment" spellcheck="true">#disable Nouveau  如果不适用nvida 驱动时需要改回</span>lsmod <span class="token operator">|</span> <span class="token function">grep</span> nouveau   <span class="token comment" spellcheck="true">#如果有输出则需要关闭</span><span class="token comment" spellcheck="true">#创建文件  vim /etc/modprobe.d/blacklist-nouveau.conf</span>blacklist nouveauoptions nouveau modeset<span class="token operator">=</span>0<span class="token comment" spellcheck="true">#then regenerate the kernel</span><span class="token function">sudo</span> update-initramfs -u<span class="token comment" spellcheck="true">#cuda 有俩中安装方式</span>    <span class="token comment" spellcheck="true"># 1: distribution-specific packages(RPM,Deb packages) recommended</span>    <span class="token comment" spellcheck="true"># 2: distribute-independent package(runfile package)  working across a wider set of linux distribution ,but doesn't update the native package management system</span><span class="token comment" spellcheck="true">#download the nvidia toolkit</span><span class="token comment" spellcheck="true"># http://develop.nvidia.com/cuda-downloads  包含 cuda 驱动和一些工具包括库,应用程序,示例程序等</span><span class="token comment" spellcheck="true">#校验下载是否正确</span>md5sum filename<span class="token comment" spellcheck="true">#具体安装下载时有说明</span><span class="token comment" spellcheck="true">#下载其他版本冲突情况看下表:</span><span class="token comment" spellcheck="true">#卸载分俩种情况</span><span class="token comment" spellcheck="true"># 1: 卸载通过 runfile  下载</span><span class="token function">sudo</span> /usr/local/cuda-x.y/bin/uninstall_cuda_x.y.pl<span class="token comment" spellcheck="true">#     卸载通过 runfile 下载的驱动</span><span class="token function">sudo</span> /usr/bin/nvidia-uninstall<span class="token comment" spellcheck="true"># 2: 卸载通过deb/RPM 包下载的软件</span><span class="token function">sudo</span> <span class="token function">apt-get</span> --purge remove <span class="token operator">&lt;</span>package_name<span class="token operator">></span> <span class="token comment" spellcheck="true"># Ubuntu</span><span class="token comment" spellcheck="true">#或者To remove CUDA Toolkit:</span>$ <span class="token function">sudo</span> <span class="token function">apt-get</span> --purge remove <span class="token string">"*cublas*"</span> <span class="token string">"cuda*"</span><span class="token comment" spellcheck="true">#To remove NVIDIA Drivers:</span>$ <span class="token function">sudo</span> <span class="token function">apt-get</span> --purge remove <span class="token string">"*nvidia*"</span><span class="token comment" spellcheck="true">#download the cuda toolkit packages https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=deblocal</span><span class="token comment" spellcheck="true">#安装cuda10.1</span><span class="token function">sudo</span> dpkg -i cuda-repo-ubuntu1804-10-1-local-10.1.168-418.67_1.0-1_amd64.deb<span class="token function">sudo</span> apt-key add /var/cuda-repo-<span class="token operator">&lt;</span>version<span class="token operator">></span>/7fa2af80.pub <span class="token comment" spellcheck="true">#本地文件，里面是一些NVidia deb安装包</span><span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> cudanvidia-smi    <span class="token comment" spellcheck="true">#查看NVIDIA 相关信息 ，这里是选择NVIDIA驱动才会显示</span><span class="token comment" spellcheck="true">#安装cuda toolkit  这和cuda 驱动没有关系</span><span class="token comment" spellcheck="true">#cudnn 在/usr/local/目录下  ； cuda_toolkit 在/usr/local/cuda-版本号</span><span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin<span class="token function">sudo</span> <span class="token function">mv</span> cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600<span class="token function">wget</span> http://developer.download.nvidia.com/compute/cuda/10.2/Prod/local_installers/cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb<span class="token function">sudo</span> dpkg -i cuda-repo-ubuntu1804-10-2-local-10.2.89-440.33.01_1.0-1_amd64.deb<span class="token function">sudo</span> apt-key add /var/cuda-repo-10-2-local-10.2.89-440.33.01/7fa2af80.pub<span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> -y <span class="token function">install</span> cuda       <span class="token comment" spellcheck="true">#下载更新cuda 和driven</span><span class="token comment" spellcheck="true">#这个步操作后，会把之前的的驱动改为418 ，这里显示驱动不匹配，把驱动删除，然后重新下载驱动，问题解决， 但是后期会不会存在问题不清楚  ，cuda10.1 对内核的要求不清楚，使用5.0.0-35 内核的，但好像不推荐</span><span class="token comment" spellcheck="true">#驱动匹配问题解决方法2:</span><span class="token function">ls</span> mod <span class="token operator">|</span> <span class="token function">grep</span> nvidia<span class="token function">sudo</span> rmmod nvidia_uvm<span class="token function">sudo</span> rmmod nvidia_modeset<span class="token function">sudo</span> rmmod nvidia<span class="token function">sudo</span> apt <span class="token function">install</span> cuda-drivers<span class="token comment" spellcheck="true">#Reboot the system to load the NVIDIA drivers.</span><span class="token comment" spellcheck="true">#Set up the development environment by modifying the PATH and LD_LIBRARY_PATH variables:</span><span class="token comment" spellcheck="true">#cuda 环境变量</span>$ <span class="token function">export</span> PATH<span class="token operator">=</span>/usr/local/cuda-10.2/bin<span class="token variable">${PATH:+:${PATH}</span><span class="token punctuation">}</span>$ <span class="token function">export</span> LD_LIBRARY_PATH<span class="token operator">=</span>/usr/local/cuda-10.2/lib64\                         <span class="token variable">${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">#Install a writable copy of the samples then build and run the nbody sample: 每一个toolkit 都有一个sample可以测试是够安装好</span>$ cuda-install-samples-10.2.sh ~$ <span class="token function">cd</span> ~/NVIDIA_CUDA-10.2_Samples/5_Simulations/nbody$ <span class="token function">make</span>$ ./nbody<span class="token comment" spellcheck="true">#运行效果如下图所示</span></code></pre><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20191212213557977.png" alt="image-20191212213557977"></p><pre class=" language-shell"><code class="language-shell">#ubuntu cudnn 安装教程 https://developer.nvidia.com/rdp/cudnn-download  cudnn其实是一些加速CUDA性能的库，首先按照解压放到CUDA的相应路径中然后把其中的lib64关联到环境变量当中#将三个deb文件都下载下同时安装，否则会报错sudo dpkg -i libcudnn7*.deb</code></pre><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20191206194750114.png" alt="image-20191206194750114"></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20191212224333748.png" alt="image-20191212224333748"></p><p>网上一个脚本</p><pre class=" language-shell"><code class="language-shell"># WARNING: These steps seem to not work anymore!#!/bin/bash# Purge existign CUDA firstsudo apt --purge remove "cublas*" "cuda*"sudo apt --purge remove "nvidia*"# Install CUDA Toolkit 10wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.debsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub && sudo apt updatesudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.debsudo apt updatesudo apt install -y cuda# Install CuDNN 7 and NCCL 2wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.debsudo dpkg -i nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.debsudo apt updatesudo apt install -y libcudnn7 libcudnn7-dev libnccl2 libc-ares-devsudo apt autoremovesudo apt upgrade# Link libraries to standard locationssudo mkdir -p /usr/local/cuda-10.0/nccl/libsudo ln -s /usr/lib/x86_64-linux-gnu/libnccl.so.2 /usr/local/cuda/nccl/lib/sudo ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.7 /usr/local/cuda-10.0/lib64/echo 'If everything worked fine, reboot now.'</code></pre><ul><li>window上查看cuda版本</li></ul><pre><code>nvcc --version   #使用命令#进入相应的目录  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA#通过Nviadia 软件查看，这里俩个版本不一致，不清楚有没有问题？</code></pre><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20200203095344007.png" alt="image-20200203095344007"></p><ul><li><h2 id="相关故障记录"><a href="#相关故障记录" class="headerlink" title="相关故障记录"></a>相关故障记录</h2></li></ul><h3 id="内核相关的"><a href="#内核相关的" class="headerlink" title="内核相关的"></a>内核相关的</h3><ol><li><p>ctrl+alt+F1–F6  切换到相应的终端</p></li><li><p><strong>file ‘which update-initramfs’</strong>  学会这个命令</p><ul><li>编译内核的最后一步执行make install时会调用update-initramfs，update-initramfs继而调用mkinitramfs生成initrd.img.  一个往临时initrd目录copy文件的繁琐过程，mkinitramfs则用脚本替代了手工操作</li><li>1).在临时initrd目录下构建FHS规定的文件系统;2).按/etc/initramfs-tools/module和/etc/modules文件的配置，往lib/modules/目录拷贝模块，同时生成模块依赖文件modules.dep，以后内核启动后会从initramfs中(initrd.img被解压到内存中)按模块依赖关系modprobe模块;3).拷贝/etc/initramfs-tools/scripts和/usr/share/initramfs-tools/scripts下的配置文件到conf/目录下,以后内核启动，创建第一个进程init(initrd.img根目录下init.sh文件)会从conf/*读取配置，按一定的顺序加载模块/执行程序;4).模块的加载离不开modprobe工具集，因此需要拷贝modprobe工具集及其他工具到initrd目录结构下，同时解决这些工具的依赖关系(依赖的so文件的路径);5).所有步骤完成，调用cpio和gzip工具打包压缩临时initrd目录结构。</li></ul></li><li><p><strong>nouveau</strong>(英语：<a href="https://baike.baidu.com/item/%2F" target="_blank" rel="noopener">/</a><a href="https://baike.baidu.com/item/n" target="_blank" rel="noopener">n</a>uːˈ<a href="https://baike.baidu.com/item/v" target="_blank" rel="noopener">v</a>oʊ<a href="https://baike.baidu.com/item/%2F" target="_blank" rel="noopener">/</a>) 是一个自由开放源代码CPU驱动程序，是为AMD的<a href="https://baike.baidu.com/item/CPU" target="_blank" rel="noopener">CPU</a>所编写，也可用于属于<a href="https://baike.baidu.com/item/系统芯片" target="_blank" rel="noopener">系统芯片</a>的<a href="https://baike.baidu.com/item/高通" target="_blank" rel="noopener">高通</a>系列.</p><p>Nouveau的内核模块应该在系统启动时就已自动加载，如果没有的话：</p><ul><li>确保你的<a href="https://wiki.archlinux.org/index.php/Kernel_parameters" target="_blank" rel="noopener">内核参数</a>中没有<code>nomodeset</code> 或者 <code>vga=</code>， 因为Nouveau需要内核模式设置。</li><li>另外，确保你没有在 modprobe 配置文件 <code>/etc/modprobe.d/</code> 或 <code>/usr/lib/modprobe.d/</code> 中屏蔽 Nouveau。</li><li>检查 dmesg 中有没有 opcode 错误，如果有的话，将 <code>nouveau.config=NvBios=PRAMIN</code> 加入 <a href="https://wiki.archlinux.org/index.php/Kernel_parameters" target="_blank" rel="noopener">内核参数</a>禁止模块卸载</li><li>Nouveau 驱动依赖<a href="https://wiki.archlinux.org/index.php/Kernel_mode_setting" target="_blank" rel="noopener">Kernel mode setting</a> (KMS)。当系统启动时，KMS 模块会在其它模块之后启用，所以显示的分辨率发生改变。</li></ul></li><li><p><strong>dmesg</strong> 命令:用来显示开机信息, kernel会将开机信息存储在ring buffer中。开机时来不及查看信息，可利用dmesg来查看。开机信息亦保存在/var/log/dmesg</p><p>1) dmesg 是一个显示内核缓冲区系统控制信息的工具;比如系统在启动时的信息会写到/var/log/</p><p>2) dmesg 命令显示Linux内核的环形缓冲区信息，我们可以从中获得诸如系统架构、CPU、挂载的硬件，RAM等多个运行级别的大量的系统信息。当计算机启动时，系统内核（操作系统的核心部分）将会被加载到内存中。在加载的过程中会显示很多的信息，在这些信息中我们可以看到内核检测硬件设备</p><p>3) dmesg 命令设备故障的诊断是非常重要的。在dmesg命令的帮助下进行硬件的连接或断开连接操作时，我们可以看到硬件的检测或者断开连接的信息</p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20191213212239267.png" alt="image-20191213212239267"></p></li><li><p>watch :  execute a program periodically, showing output fullscreen  <font color="red">watch “dmesg | tail -20” </font></p></li><li><p><strong>rmmod</strong>: 可删除不需要的模块。Linux操作系统的核心具有模块化的特性，因此在编译核心时，不需要把全部的功能都放入核心。</p></li><li><p><strong>lsmod</strong>: 显示内核中的模块作用同 <strong>cat /proc/devices</strong> </p></li><li><p><strong>modinfo</strong> 能查看模块的信息，通过查看模块信息来判定这个模块的用途；</p></li><li><p><strong>insmod</strong>: 向linux 内核中加载摸块  </p></li><li><p><strong>modprobe</strong> :向Linux内核中加载摸块,能够处理 module 载入的相依问题.  <font color="red">modprobe会检查/lib/modules/<code>uname -r</code>下的所有模块，除了/etc/modprobe.conf配置文件和/etc/modprobe.d目录以外。所有/etc/modprobe.d/arch/目录下的文件将被忽略。</font></p></li><li><p><font color="red">unable to correct problems,you have held broken package</font>    </p><pre class=" language-shell"><code class="language-shell">sudo apt install -fsudo aptitude install <packagename>  #get the detail informationsudo apt update  | sudo apt upgradesudo dpkg --configure -asudo dpkg --get-selection | grep hold #get actual held packagesdpkg --get-selections | grep linux-image  #产看内核文件有哪些</code></pre></li></ol><ol start="12"><li><p>Grub2介绍</p><ul><li>/boot/grub/grub.cfg 文件<ul><li>官方文件只说/boot/grub/grub.cfg不要手工修改，这个文件是运行 update-grub自动生成的。要修改配置文件的只要打开/boot/grub/grub.cfg文件，找到想修改的地方，然后根据注释找到相应的 /etc/default/grub或/etc/grub.d/ (folder)进行修改。</li><li>grub.cfg文件中主要包含两个部分，一部分是 各个启动项的定义，第二部分是启动界面的设置。你可以直接用gedit打开该文件看其中的内容。</li></ul></li><li>/etc/grub.d/ 文件夹<ul><li>定义各个启动项，其中的文件代表了一个或多个启动项，命名规范都是”两个数字<em>名称”，前面的两位数字确定这个或这多个启动项在启动界面的位置， 默认的 “00</em>“是预留给”00_header”的，”10_是预留给当前系统内核的，20_是预留给第三方程序的，除了这些你都可以使用，增加自己的，比如 05_ , 15_，数字越小越前面。</li><li>执行前面说的”update-grub”或者update- grub2”命令之后，这个文件夹中的文件就是用于生成 grub.cfg 中启动项的定义的</li></ul></li><li>/etc/default/grub 文件<ul><li>启动界面的配置，比如默认的启动项，等待用户选择启动项的时间等。当执行前面说的”update-grub”或者update-grub2”命令之后，这个文件的内容就 用于生成 grub.cfg 中启动界面的设置。</li></ul></li></ul></li><li><p>内核降级</p></li></ol><ul><li><p><strong>linux-image-</strong>: 内核镜像</p></li><li><p><strong>linux-image-extra-</strong>: 额外的内核模块</p></li><li><p><strong>linux-headers-</strong>: 内核头文件</p></li><li><p><a href="https://www.kernel.org/" target="_blank" rel="noopener">https://www.kernel.org/</a>  查看稳定的内核</p></li><li><p>官网: <a href="https://kernel.ubuntu.com/~kernel-ppa/mainline/" target="_blank" rel="noopener">https://kernel.ubuntu.com/~kernel-ppa/mainline/</a>  以及相应内核安装位置</p></li><li><p>安装4.19</p><ul><li>wget -c <a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-headers-4.19.0-041900_4.19.0-041900.201810221809_all.deb" target="_blank" rel="noopener">http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-headers-4.19.0-041900_4.19.0-041900.201810221809_all.deb</a></li></ul><p>wget -c <a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-headers-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb" target="_blank" rel="noopener">http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-headers-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb</a></p><p>wget -c <a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-image-unsigned-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb" target="_blank" rel="noopener">http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-image-unsigned-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb</a></p><p>wget -c <a href="http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-modules-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb" target="_blank" rel="noopener">http://kernel.ubuntu.com/~kernel-ppa/mainline/v4.19/linux-modules-4.19.0-041900-generic_4.19.0-041900.201810221809_amd64.deb</a></p><p>sudo dpkg -i *.deb</p></li></ul><pre class=" language-shell"><code class="language-shell">#查看可用的内核apt-cache search linux-image#备份软件源sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak#添加一个源sudo vim /etc/apt/sources.listdeb http://security.ubuntu.com/ubuntu trusty-security mainsudo apt update#查看所有内核dpkg --get-selections| grep linux#安装指定版本内核sudo apt install 内核名称<linux-image-4.4.0-75-generic>dpkg -l | grep 内核名称<linux-image-extra-3.16.0-43-generic>  #查看是否安装成功#编辑grub 文件GRUB_DEFAULT=0GRUB_DEFAULT="Advanced options for Ubuntu>Ubuntu, with Linux 内核名称<5.0.0-36-generic>"Ubuntu,with Linux 5.3.0-25-generic#更新grub 引导sudo update-grubsudo rebootuname -r #查看当前版本是否安装正确#卸载内核sudo apt remove --purge 内核名称<linux-image-extra-3.16.0-43-generic>sudo dpkg --purge linux-image-4.19.0-041900-generic linux-image-unsigned-4.19.0-041900-genericsudo dpkg -P 内核名称  #通过deb包暗装的#关闭启动内核自动更新sudo apt-mark hold linux-image-generic linux-headers-genericsudo apt-mark unhold linux-image-generic linux-headers-generic</code></pre><p>使用指定版本内核  /boot 文件是内核相关的信息</p><ul><li><pre><code>grep menuentry /boot/grub/grub.cfg</code></pre></li></ul><p>例如文件如下:</p><pre><code>if [ x"${feature_menuentry_id}" = xy ]; then  menuentry_id_option="--id"  menuentry_id_option=""export menuentry_id_optionmenuentry 'Ubuntu' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-5bce3795-da96-4c6f-bed2-67d37185a77d' {submenu 'Ubuntu 高级选项' $menuentry_id_option 'gnulinux-advanced-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu，Linux 4.8.0-26-lowlatency' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-lowlatency-advanced-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.8.0-26-lowlatency (upstart)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-lowlatency-init-upstart-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.8.0-26-lowlatency (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-lowlatency-recovery-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu，Linux 4.8.0-26-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-generic-advanced-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.8.0-26-generic (upstart)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-generic-init-upstart-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.8.0-26-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-45-generic-recovery-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu，Linux 4.4.0-21-generic' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-21-generic-advanced-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.4.0-21-generic (upstart)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-21-generic-init-upstart-5bce3795-da96-4c6f-bed2-67d37185a77d' {    menuentry 'Ubuntu, with Linux 4.4.0-21-generic (recovery mode)' --class ubuntu --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.4.0-21-generic-recovery-5bce3795-da96-4c6f-bed2-67d37185a77d' {menuentry 'Memory test (memtest86+)' {menuentry 'Memory test (memtest86+, serial console 115200)' {</code></pre><p>menuentry 代表一个内核, 从0开始记数字: 例如如果使用<strong>以4.4.0-21内核版本启动，则将文件/etc/default/grub中</strong></p><pre><code>GRUB_DEFAULT=0 </code></pre><p>改为 </p><pre><code>GRUB_DEFAULT=6</code></pre><p>或者改为</p><pre><code>GRUB_DEFAULT=”Ubuntu，Linux 4.4.0-21-generic“</code></pre><ul><li><strong>sudo update-grub</strong> 然后重启执行uname -r  查看系统内核</li></ul><ol><li><font color="red">Nouveau unknown chipset at install </font>  显卡驱动问题</li></ol><pre class=" language-shell"><code class="language-shell">sudo apt updatesudo apt upgradesudo ubuntu-drivers devicessudo apt install nvidia-xxx#如果没有NVIDIA驱动的话,  </code></pre><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a><strong>文件</strong></h3><ul><li><p>/boot 文件:  系统内核文件 ,启动管理程序grub 的目录</p><ul><li>Initrd 文件,系统启动摸块的只要来源,系统启动所需加载的虚拟磁盘</li><li>System.map 系统内核中的变量对应表</li><li>vmlinuz 是启动过程系统实际所用的内核</li><li>grub目录是启动管理程序的<ul><li>grub.conf 文件 从哪个内核进入,启动时间等</li></ul></li><li>kernel kernel主要负责的是北桥、南桥、CPU及内存，可见它们都是整个主机最重要的硬件核心部分，kernel如果处了问题，系统肯定无法启动起来。</li><li>kernel、initrd和system module是依次加载的。initrd包含一部分内核模块，主要是一些关键的外部硬件，如SATA、SCSI和USB等外设。它如果失败当然也会影响系统启动。而system module这些系统中的模块，是与支持和启动无很大关系的硬件有关，如果没有这些硬件设备的支持，系统也可以启动完成，只是存在功能上的缺失，如声卡、网卡、显卡等。这些系统模块也可以在启动后，以modprobe</li></ul></li><li><p>/lib 标准程序设计库，又叫动态链接共享库，作用类似windows里的.dll文件</p></li><li><p>/sbin 系统管理命令，这里存放的是系统管理员使用的管理程序</p></li><li><p>/bin 二进制可执行命令<br>/dev 设备特殊文件<br>/etc 系统管理和配置文件<br>/etc/rc.d 启动的配置文件和脚本</p></li><li><p>/lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里</p></li><li><p>/usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录。其中包含：<br>/usr/x11r6 存放x window的目录<br>/usr/bin 众多的应用程序<br>/usr/sbin 超级用户的一些管理程序<br><strong>/usr/include linux下开发和编译应用程序所需要的头文件</strong><br><strong>/usr/lib 常用的动态链接库和软件包的配置文件</strong><br><strong>/usr/doc linux文档</strong> /usr/man 帮助文档  /usr/info<br><strong>/usr/src 源代码，linux内核的源代码就放在/usr/src/linux里</strong><br><strong>/usr/local/bin 本地增加的命令</strong><br><strong>/usr/local/lib 本地增加的库</strong></p><p><img src="https://gitee.com/github-25970295/blogImage/raw/master/img/image-20191213221715677.png" alt="image-20191213221715677"></p><p>/var 包含系统一般运行时要改变的数据。通常这些数据所在的目录的大小是要经常变化<br>或扩充的。原来/ v a r目录中有些内容是在/ u s r中的，但为了保持/ u s r目录的相对稳定，就把那<br>些需要经常改变的目录放到/ v a r中了。每个系统是特定的，即不通过网络与其他计算机共享。</p><ul><li>/var/log:各种程序的日志( l o g )文件，尤其是login (/var/log/wtmp log纪录所有到系统的登录和注<br>销) 和syslog (/var/log/messages 纪录存储所有核心和系统程序信息)。/var/log 里的文件经常不<br>确定地增长，应该定期清除。</li></ul><p>/proc文件系统<br>/proc 文件系统是一个伪的文件系统，就是说它是一个实际上不存在的目录，因而这是一<br>个非常特殊的目录。它并不存在于某个磁盘上，而是由核心在内存中产生。这个目录用于提<br>供关于系统的信息。下面说明一些最重要的文件和目录(/proc 文件系统在proc man页中有更详<br>细的说明)。<br>\1. /proc/x<br>关于进程x的信息目录，这一x是这一进程的标识号。每个进程在/proc 下有一个名为自<br>己进程号的目录。<br>\2. /proc/cpuinfo<br>存放处理器( c p u )的信息，如c p u的类型、制造商、型号和性能等。<br>\3. /proc/devices<br>当前运行的核心配置的设备驱动的列表。<br>\4. /proc/dma<br>显示当前使用的d m a通道。<br>\5. /proc/filesystems<br>核心配置的文件系统信息。<br>\6. /proc/interrupts<br>显示被占用的中断信息和占用者的信息，以及被占用的数量。<br>\7. /proc/ioports<br>当前使用的i / o端口。<br>\8. /proc/kcore<br>系统物理内存映像。与物理内存大小完全一样，然而实际上没有占用这么多内存；它仅<br>仅是在程序访问它时才被创建。(注意：除非你把它拷贝到什么地方，否则/proc 下没有任何<br>东西占用任何磁盘空间。)<br>\9. /proc/kmsg<br>核心输出的消息。也会被送到s y s l o g。<br>\10. /proc/ksyms<br>核心符号表。<br>\11. /proc/loadavg<br>系统“平均负载”； 3个没有意义的指示器指出系统当前的工作量。<br>\12. /proc/meminfo<br>各种存储器使用信息，包括物理内存和交换分区( s w a p )。<br>\13. /proc/modules<br>存放当前加载了哪些核心模块信息。<br>\14. /proc/net<br>网络协议状态信息。<br>\15. /proc/self<br>存放到查看/proc 的程序的进程目录的符号连接。当2个进程查看/proc 时，这将会是不同<br>的连接。这主要便于程序得到它自己的进程目录。<br>\16. /proc/stat<br>系统的不同状态，例如，系统启动后页面发生错误的次数。<br>\17. /proc/uptime<br>系统启动的时间长度。<br>\18. /proc/version<br>核心版本。</p></li></ul><ol><li><p><strong>ACPI在</strong>BIOS和其他系统硬件中被实现，它就可以由操作系统所调用(触发)。</p><p>ACPI可以实现的功能包括：</p><p>系统电源管理（System power management）</p><p>设备电源管理（Device power management）</p><p>处理器电源管理（Processor power management）</p><p>设备和处理器性能管理（Device and processor performance management）</p><p>配置/即插即用（Configuration/Plug and Play）</p><p>系统事件（System Event）</p><p>电池管理（Battery management）</p><p>温度管理（Thermal management）</p><p><a href="https://baike.baidu.com/item/嵌入式控制器" target="_blank" rel="noopener">嵌入式控制器</a>（Embedded Controller）</p><p>SMBus控制器（SMBus Controller</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OperationSystem </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Vue Style Typora Theme</title>
      <link href="/2018/11/19/ruan-jian-gong-ju/hexotypora/vue-wen-dang-feng-ge-de-typora-zhu-ti/"/>
      <url>/2018/11/19/ruan-jian-gong-ju/hexotypora/vue-wen-dang-feng-ge-de-typora-zhu-ti/</url>
      
        <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/blinkfox/typora-vue-theme" target="_blank" rel="noopener">typora-vue-theme</a> 是 Typora Markdown 文档编辑器中一款类似<a href="https://vuejs.org/" target="_blank" rel="noopener">Vue</a>文档风格的主题。</p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://www.typora.io/" target="_blank" rel="noopener">Typora</a>是一款支持实时预览的 Markdown 编辑器和阅读器，支持<code>Windows</code>、<code>macOS</code>、<code>Linux</code>三大平台。Typora 作为一款合格的 Markdown 编辑器，支持图片、列表、表格、代码、公式、目录等功能，同时这款软件还支持（一键）动态预览功能，让一切都变得如此干净、纯粹。并且有多种主题模板。<strong><a href="https://github.com/blinkfox/typora-vue-theme" target="_blank" rel="noopener">typora-vue-theme</a>就是参考了<a href="https://vuejs.org/" target="_blank" rel="noopener">Vue</a>文档风格而开发的一个 Typora 自定义主题</strong>。</p><h2 id="安装主题"><a href="#安装主题" class="headerlink" title="安装主题"></a>安装主题</h2><ol><li>下载本主题中的<code>vue.css</code>、<code>vue-dark.css</code>文件和包含字体的<code>vue</code>文件夹；</li><li>打开 Typora，点击“<strong>偏好设置</strong>” =&gt; “<strong>打开主题文件夹</strong>”按钮，将弹出 Typora 的主题文件夹；</li><li>将下载好的<code>vue.css</code>和<code>vue-dark.css</code>文件和包含字体的<code>vue</code>文件夹放到 Typora 的主题文件夹中；</li><li>关闭并重新打开 Typora，从菜单栏中选择 “<strong>主题</strong>” =&gt; “<strong>Vue</strong>” 或者 “<strong>Vue Dark</strong>” 即可。</li></ol><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p><img src="http://static.blinkfox.com/typora_vue_theme_screen_01.png" alt=""></p><p><img src="http://static.blinkfox.com/typora_vue_theme_screen_02.png" alt=""></p><p><img src="http://static.blinkfox.com/typora_vue_theme_screen_03.png" alt=""></p><h3 id="Vue-Dark"><a href="#Vue-Dark" class="headerlink" title="Vue Dark"></a>Vue Dark</h3><p><img src="https://github.com/MamoruDS/typora-vue-theme/raw/master/screenshots/screenshot_01.png" alt=""></p><p><img src="https://github.com/MamoruDS/typora-vue-theme/raw/master/screenshots/screenshot_02.png" alt=""></p><blockquote><p><strong>感谢</strong>: 本主题中的<code>vue-dark.css</code>来自<a href="https://github.com/MamoruDS/typora-vue-dark-theme" target="_blank" rel="noopener">typora-vue-dark-theme</a>.</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 软件工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Typora </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
